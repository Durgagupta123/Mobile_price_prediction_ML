{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb230aaa",
   "metadata": {},
   "source": [
    "# Ensembling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a455b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Naive Aggregation \\na. Hard Voting      \\nb. Soft voting\\n\\n2. Bootstrapping\\na. Bagging   b. pasting   c.Random Forest Tree\\n\\n3. Boosting Technique\\na. ADA Boost (Adaptor Boosting)\\nb. Gradient Boosting\\nc. Extreme Gradient Boosting(XG Boost)\\n\\n4. Stacking\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensembling Technique : -\n",
    "#There are different types of Ensembling technique\n",
    "'''\n",
    "1. Naive Aggregation \n",
    "a. Hard Voting      \n",
    "b. Soft voting\n",
    "\n",
    "2. Bootstrapping\n",
    "a. Bagging   b. pasting   c.Random Forest Tree\n",
    "\n",
    "3. Boosting Technique\n",
    "a. ADA Boost (Adaptor Boosting)\n",
    "b. Gradient Boosting\n",
    "c. Extreme Gradient Boosting(XG Boost)\n",
    "\n",
    "4. Stacking\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4abbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling Technique : -\n",
    "#Bootstraping\n",
    "#RandomForestTree\n",
    "#work on dataset bank.csv\n",
    "#Classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10ceaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load dataset\n",
    "df = pd.read_csv(\"bank (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b00d2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To display first 5 record\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ac24f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4aeb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          int64\n",
       "job          int64\n",
       "marital      int64\n",
       "education    int64\n",
       "default      int64\n",
       "balance      int64\n",
       "housing      int64\n",
       "loan         int64\n",
       "contact      int64\n",
       "day          int64\n",
       "month        int64\n",
       "duration     int64\n",
       "campaign     int64\n",
       "pdays        int64\n",
       "previous     int64\n",
       "poutcome     int64\n",
       "deposit      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross check with data type\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ad033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check duplicates row\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d996da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here target : deposite that means we predict whether the customer will\n",
    "#subscribe the term deposit or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510bce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many category in deposite column\n",
    "df[\"deposit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b57e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5873\n",
       "1    5289\n",
       "Name: deposit, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many sample for 1 and 0 in target column deposit\n",
    "f = df[\"deposit\"].value_counts()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a42c313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualise form\n",
    "sb.countplot(data=df,x='deposit')\n",
    "plt.yticks(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a03798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output from given dataset\n",
    "x = df.drop('deposit',axis=1)    #input\n",
    "y = df['deposit']    #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b765165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47abf23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,\n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a287a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7813, 16), (7813,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a349535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3349, 16), (3349,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890c668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply scaling on input x_train and x_test\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b32b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object for StandardScaler class\n",
    "ss = StandardScaler()\n",
    "\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8f447b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user define function\n",
    "def create_model(model):\n",
    "    model.fit(x_train,y_train) #train the model with 70% data\n",
    "    y_pred = model.predict(x_test)  #model test with 30% data\n",
    "    \n",
    "    #generate Report\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2056f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac069770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frist use LogisticRegression Alog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a11df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de3f1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object for LogisticRegression class\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2423906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.79      0.77      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 359 1230]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "lr = create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10534053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#got recall 0.77(77%) , it is good but not better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36373431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second DecisionTreeClassifier with gini index\n",
    "#Now, give data in the next classification algo. DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56a9e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object for DecisionTreeClassifier class\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "#by default GINI Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a45f2544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1760\n",
      "           1       0.78      0.77      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1407  353]\n",
      " [ 372 1217]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dtc = create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c704e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.354008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month</td>\n",
       "      <td>0.098357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.084437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>0.077136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day</td>\n",
       "      <td>0.076581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.061793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.047856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.042620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.036110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job</td>\n",
       "      <td>0.034220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.025851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.022316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.016968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education</td>\n",
       "      <td>0.014356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.006934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.354008\n",
       "1       month  0.098357\n",
       "2     balance  0.084437\n",
       "3         age  0.077136\n",
       "4         day  0.076581\n",
       "5     contact  0.061793\n",
       "6       pdays  0.047856\n",
       "7     housing  0.042620\n",
       "8    poutcome  0.036110\n",
       "9         job  0.034220\n",
       "10   previous  0.025851\n",
       "11   campaign  0.022316\n",
       "12    marital  0.016968\n",
       "13  education  0.014356\n",
       "14       loan  0.006934\n",
       "15    default  0.000456"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check information gain :\n",
    "dict = {\"Input\":x.columns,\"IG\":dtc.feature_importances_}\n",
    "df1 = pd.DataFrame(dict)\n",
    "df1.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90b93f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a tree\n",
    "#import the inbuilt class tree from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "feature = x.columns\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "#_ = tree.plot_tree(dtc,feature_names=feature,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a711338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#But we got less score 0.77 % its good but not excellent , \n",
    "#region behind less score , overfit means \n",
    "#model is overfit so reduced the overfitting situation : - \n",
    "#then we use pruning technique \n",
    "\n",
    "#How to reduced a overfitting situation By using the Pruning technique : -\n",
    "#There are 2 types of pruning technique : -\n",
    "#1. max_depth : inbulit parameter of DecisionTreeClassifier class\n",
    "#2. min_samples_leaf  : inbuilt parameter of DecisionTreeClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a05708b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1760\n",
      "           1       0.66      0.81      0.73      1589\n",
      "\n",
      "    accuracy                           0.71      3349\n",
      "   macro avg       0.72      0.72      0.71      3349\n",
      "weighted avg       0.73      0.71      0.71      3349\n",
      "\n",
      "[[1092  668]\n",
      " [ 296 1293]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1760\n",
      "           1       0.66      0.81      0.73      1589\n",
      "\n",
      "    accuracy                           0.71      3349\n",
      "   macro avg       0.72      0.72      0.71      3349\n",
      "weighted avg       0.73      0.71      0.71      3349\n",
      "\n",
      "[[1092  668]\n",
      " [ 296 1293]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      1760\n",
      "           1       0.71      0.86      0.78      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.78      0.78      0.77      3349\n",
      "weighted avg       0.78      0.77      0.77      3349\n",
      "\n",
      "[[1212  548]\n",
      " [ 218 1371]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1760\n",
      "           1       0.77      0.79      0.78      1589\n",
      "\n",
      "    accuracy                           0.79      3349\n",
      "   macro avg       0.78      0.79      0.78      3349\n",
      "weighted avg       0.79      0.79      0.79      3349\n",
      "\n",
      "[[1377  383]\n",
      " [ 337 1252]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80      1760\n",
      "           1       0.75      0.86      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1316  444]\n",
      " [ 228 1361]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1352  408]\n",
      " [ 259 1330]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1760\n",
      "           1       0.81      0.80      0.80      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1454  306]\n",
      " [ 313 1276]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1760\n",
      "           1       0.81      0.80      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 312 1277]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Pruning technique :\n",
    "#1.max_depth : the value of max depth cannot be more the 8 i.e. means<=8\n",
    "#create object for DecisionTreeClassifier class with gini index and use parameter max_depth\n",
    "#To remove overfitting\n",
    "\n",
    "#let use loop for checking the value of max_depth\n",
    "for i in range(1,9):\n",
    "    dtc = DecisionTreeClassifier(random_state=1,max_depth=i)  #by default gini index\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    dtc = create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56b4ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1760\n",
      "           1       0.81      0.80      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1465  295]\n",
      " [ 312 1277]]\n"
     ]
    }
   ],
   "source": [
    "#We use max_depth = 5\n",
    "dtc2 = DecisionTreeClassifier(random_state=1,max_depth=5)\n",
    "#call function\n",
    "dtc2 = create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54a7ff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.477684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.101254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.083332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.069480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.064248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.057849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>0.049757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0.030163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.022758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.020437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>job</td>\n",
       "      <td>0.009189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education</td>\n",
       "      <td>0.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.003627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.477684\n",
       "1     contact  0.101254\n",
       "2       month  0.083332\n",
       "3     housing  0.069480\n",
       "4       pdays  0.064248\n",
       "5    poutcome  0.057849\n",
       "6         age  0.049757\n",
       "7         day  0.030163\n",
       "8    previous  0.022758\n",
       "9     balance  0.020437\n",
       "10        job  0.009189\n",
       "11  education  0.004046\n",
       "12       loan  0.003627\n",
       "13   campaign  0.002821\n",
       "14    marital  0.002579\n",
       "15    default  0.000776"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain:\n",
    "dict1 = {\"Input\":x.columns,\"IG\":dtc2.feature_importances_}\n",
    "df2 = pd.DataFrame(dict1)\n",
    "df2.sort_values('IG',ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35e7bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min samples leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1378  382]\n",
      " [ 204 1385]]\n",
      "Min samples leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1760\n",
      "           1       0.79      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 212 1377]]\n",
      "Min samples leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1760\n",
      "           1       0.79      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 212 1377]]\n",
      "Min samples leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83      1760\n",
      "           1       0.79      0.86      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1397  363]\n",
      " [ 224 1365]]\n",
      "Min samples leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 245 1344]]\n",
      "Min samples leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 242 1347]]\n",
      "Min samples leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 242 1347]]\n",
      "Min samples leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1412  348]\n",
      " [ 242 1347]]\n",
      "Min samples leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 258 1331]]\n",
      "Min samples leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 259 1330]]\n",
      "Min samples leaf: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1402  358]\n",
      " [ 257 1332]]\n",
      "Min samples leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 269 1320]]\n",
      "Min samples leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 278 1311]]\n",
      "Min samples leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 278 1311]]\n",
      "Min samples leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 278 1311]]\n",
      "Min samples leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 278 1311]]\n",
      "Min samples leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 277 1312]]\n",
      "Min samples leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 277 1312]]\n",
      "Min samples leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1422  338]\n",
      " [ 274 1315]]\n",
      "Min samples leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.82      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 263 1326]]\n",
      "Min samples leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.82      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 263 1326]]\n",
      "Min samples leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1385  375]\n",
      " [ 257 1332]]\n",
      "Min samples leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1391  369]\n",
      " [ 256 1333]]\n",
      "Min samples leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1405  355]\n",
      " [ 267 1322]]\n",
      "Min samples leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1404  356]\n",
      " [ 267 1322]]\n",
      "Min samples leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 270 1319]]\n",
      "Min samples leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 270 1319]]\n",
      "Min samples leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 268 1321]]\n",
      "Min samples leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      1760\n",
      "           1       0.77      0.83      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1370  390]\n",
      " [ 269 1320]]\n",
      "Min samples leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      1760\n",
      "           1       0.77      0.83      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1370  390]\n",
      " [ 269 1320]]\n",
      "Min samples leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81      1760\n",
      "           1       0.77      0.83      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1370  390]\n",
      " [ 270 1319]]\n",
      "Min samples leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1403  357]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1403  357]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1404  356]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1404  356]\n",
      " [ 279 1310]]\n",
      "Min samples leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82      1760\n",
      "           1       0.79      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1406  354]\n",
      " [ 280 1309]]\n",
      "Min samples leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1433  327]\n",
      " [ 308 1281]]\n",
      "Min samples leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1433  327]\n",
      " [ 308 1281]]\n",
      "Min samples leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1433  327]\n",
      " [ 308 1281]]\n",
      "Min samples leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1760\n",
      "           1       0.79      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 307 1282]]\n",
      "Min samples leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1760\n",
      "           1       0.79      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 307 1282]]\n",
      "Min samples leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81      1760\n",
      "           1       0.79      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 307 1282]]\n"
     ]
    }
   ],
   "source": [
    "#2.Now using 2nd purning tectnique: min_samples_leaf \n",
    "#its an inbuilt parameter of DecisionTreeClassifier class , it is also use to remove overfitting\n",
    "#Leaf means no tree\n",
    "#create an object for DecisionTreeClassifier class\n",
    "#1st apply loop for check the value in min_samples_leaf\n",
    "for i in range(45,101):\n",
    "    dt3 = DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min samples leaf:\",i)\n",
    "    #call function\n",
    "    dt3 = create_model(dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209a6600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.83      1760\n",
      "           1       0.78      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1379  381]\n",
      " [ 204 1385]]\n"
     ]
    }
   ],
   "source": [
    "#we use min_samples_depth=45\n",
    "dt3 = DecisionTreeClassifier(random_state=1,min_samples_leaf=45)\n",
    "#Call function\n",
    "dt3 = create_model(dt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f9b100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.496317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month</td>\n",
       "      <td>0.109126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.105357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.068329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.059375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.044066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>0.043918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.036294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.021749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.005046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>job</td>\n",
       "      <td>0.004888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.003143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>education</td>\n",
       "      <td>0.001979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.496317\n",
       "1       month  0.109126\n",
       "2     contact  0.105357\n",
       "3     housing  0.068329\n",
       "4    poutcome  0.059375\n",
       "5       pdays  0.044066\n",
       "6         age  0.043918\n",
       "7    previous  0.036294\n",
       "8     balance  0.021749\n",
       "9         day  0.005046\n",
       "10        job  0.004888\n",
       "11       loan  0.003143\n",
       "12  education  0.001979\n",
       "13   campaign  0.000412\n",
       "14    marital  0.000000\n",
       "15    default  0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain\n",
    "dict = {\"Input\":x.columns,\"IG\":dt3.feature_importances_}\n",
    "df3 = pd.DataFrame(dict)\n",
    "df3.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b237eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here recall value is 0.87 maens 87% (DTC with GINI Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cddcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next DecisionTreeClassifier with Entropy\n",
    "#1st create an object for DecisionTreeClassifier class\n",
    "dt_entropy = DecisionTreeClassifier(random_state=1,criterion=\"entropy\")\n",
    "#by default its take gini index , if not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3cef504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      1760\n",
      "           1       0.79      0.75      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1433  327]\n",
      " [ 394 1195]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "dt_entropy = create_model(dt_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f387a0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.311218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>month</td>\n",
       "      <td>0.110721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.094507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>day</td>\n",
       "      <td>0.090688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.086951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.076067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.046928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.032042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>job</td>\n",
       "      <td>0.028838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.027159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education</td>\n",
       "      <td>0.025337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.022520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.022261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.014123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.311218\n",
       "1       month  0.110721\n",
       "2     balance  0.094507\n",
       "3         day  0.090688\n",
       "4         age  0.086951\n",
       "5     contact  0.076067\n",
       "6       pdays  0.046928\n",
       "7     housing  0.032042\n",
       "8         job  0.028838\n",
       "9    campaign  0.027159\n",
       "10  education  0.025337\n",
       "11   poutcome  0.022520\n",
       "12   previous  0.022261\n",
       "13    marital  0.014123\n",
       "14       loan  0.009852\n",
       "15    default  0.000788"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain :\n",
    "dict2 = {\"Input\":x.columns,\"IG\":dt_entropy.feature_importances_}\n",
    "df4 = pd.DataFrame(dict2)\n",
    "df4.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b32ced92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a tree \n",
    "features = x.columns\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "#_ = tree.plot_tree(dt_entropy,feature_names=features,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6f8bdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1760\n",
      "           1       0.66      0.81      0.73      1589\n",
      "\n",
      "    accuracy                           0.71      3349\n",
      "   macro avg       0.72      0.72      0.71      3349\n",
      "weighted avg       0.73      0.71      0.71      3349\n",
      "\n",
      "[[1092  668]\n",
      " [ 296 1293]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1760\n",
      "           1       0.66      0.81      0.73      1589\n",
      "\n",
      "    accuracy                           0.71      3349\n",
      "   macro avg       0.72      0.72      0.71      3349\n",
      "weighted avg       0.73      0.71      0.71      3349\n",
      "\n",
      "[[1092  668]\n",
      " [ 296 1293]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1760\n",
      "           1       0.72      0.80      0.76      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.76      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1261  499]\n",
      " [ 310 1279]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79      1760\n",
      "           1       0.76      0.76      0.76      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.77      0.77      0.77      3349\n",
      "weighted avg       0.77      0.77      0.77      3349\n",
      "\n",
      "[[1385  375]\n",
      " [ 381 1208]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      1760\n",
      "           1       0.75      0.79      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1342  418]\n",
      " [ 328 1261]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1760\n",
      "           1       0.77      0.81      0.79      1589\n",
      "\n",
      "    accuracy                           0.79      3349\n",
      "   macro avg       0.79      0.79      0.79      3349\n",
      "weighted avg       0.79      0.79      0.79      3349\n",
      "\n",
      "[[1364  396]\n",
      " [ 298 1291]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      1760\n",
      "           1       0.81      0.78      0.79      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.80      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1462  298]\n",
      " [ 351 1238]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1760\n",
      "           1       0.80      0.79      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1449  311]\n",
      " [ 330 1259]]\n"
     ]
    }
   ],
   "source": [
    "#we got less score 75% its good but not excellent, reason behind the score is overfitting\n",
    "#means model is overfit so to reduce the overfitting situation we use pruning tech.\n",
    "#i.e. max_depth and min_samples_leaf\n",
    "\n",
    "#by using max_depth between range 1 to 8 we use loop \n",
    "for i in range(1,9):\n",
    "    dt1_entropy = DecisionTreeClassifier(random_state=1,max_depth=i,criterion=\"entropy\")\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    dt1_entropy = create_model(dt1_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a90a79ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82      1760\n",
      "           1       0.80      0.79      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1449  311]\n",
      " [ 330 1259]]\n"
     ]
    }
   ],
   "source": [
    "#we use max_depth=6 \n",
    "dt1 = DecisionTreeClassifier(random_state=1,max_depth=6,criterion=\"entropy\")\n",
    "#call function\n",
    "dt1_entropy = create_model(dt1_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf2e1e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.472495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.141147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.125603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.072249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.054594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>0.033594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.029269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0.024655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.015845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job</td>\n",
       "      <td>0.010456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education</td>\n",
       "      <td>0.007431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.006056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.472495\n",
       "1     contact  0.141147\n",
       "2       month  0.125603\n",
       "3       pdays  0.072249\n",
       "4     housing  0.054594\n",
       "5         age  0.033594\n",
       "6    poutcome  0.029269\n",
       "7         day  0.024655\n",
       "8     balance  0.015845\n",
       "9         job  0.010456\n",
       "10  education  0.007431\n",
       "11   campaign  0.006056\n",
       "12       loan  0.003790\n",
       "13   previous  0.002123\n",
       "14    marital  0.000694\n",
       "15    default  0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain\n",
    "dict3 = {\"Input\":x.columns,\"IG\":dt1_entropy.feature_importances_}\n",
    "df5 = pd.DataFrame(dict3)\n",
    "df5.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0cf2e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min sample leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 283 1306]]\n",
      "Min sample leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 283 1306]]\n",
      "Min sample leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 267 1322]]\n",
      "Min sample leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      1760\n",
      "           1       0.80      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 267 1322]]\n",
      "Min sample leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 274 1315]]\n",
      "Min sample leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1450  310]\n",
      " [ 285 1304]]\n",
      "Min sample leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.81      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1448  312]\n",
      " [ 288 1301]]\n",
      "Min sample leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.81      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1448  312]\n",
      " [ 288 1301]]\n",
      "Min sample leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 292 1297]]\n",
      "Min sample leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 292 1297]]\n",
      "Min sample leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 291 1298]]\n",
      "Min sample leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 290 1299]]\n",
      "Min sample leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 290 1299]]\n",
      "Min sample leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 290 1299]]\n",
      "Min sample leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 288 1301]]\n",
      "Min sample leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 287 1302]]\n",
      "Min sample leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 300 1289]]\n",
      "Min sample leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1760\n",
      "           1       0.82      0.80      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1472  288]\n",
      " [ 311 1278]]\n",
      "Min sample leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      1760\n",
      "           1       0.82      0.80      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1472  288]\n",
      " [ 311 1278]]\n",
      "Min sample leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1760\n",
      "           1       0.81      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1464  296]\n",
      " [ 306 1283]]\n",
      "Min sample leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 294 1295]]\n",
      "Min sample leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 294 1295]]\n",
      "Min sample leaf: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 296 1293]]\n",
      "Min sample leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 278 1311]]\n",
      "Min sample leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 278 1311]]\n",
      "Min sample leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 277 1312]]\n",
      "Min sample leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.80      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 277 1312]]\n",
      "Min sample leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1407  353]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 270 1319]]\n",
      "Min sample leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1406  354]\n",
      " [ 269 1320]]\n",
      "Min sample leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1406  354]\n",
      " [ 269 1320]]\n",
      "Min sample leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1395  365]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1394  366]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.78      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1393  367]\n",
      " [ 257 1332]]\n",
      "Min sample leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 251 1338]]\n",
      "Min sample leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1358  402]\n",
      " [ 250 1339]]\n",
      "Min sample leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.81      0.81      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1354  406]\n",
      " [ 248 1341]]\n",
      "Min sample leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.81      0.81      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1354  406]\n",
      " [ 248 1341]]\n",
      "Min sample leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.81      0.81      0.80      3349\n",
      "weighted avg       0.81      0.80      0.80      3349\n",
      "\n",
      "[[1354  406]\n",
      " [ 248 1341]]\n",
      "Min sample leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      1760\n",
      "           1       0.77      0.84      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1355  405]\n",
      " [ 248 1341]]\n"
     ]
    }
   ],
   "source": [
    "#Now using 2nd pruning technique : min_samples_leaf\n",
    "#to check the min samples leaf between 45 to 100 we use loop\n",
    "for i in range(45,101):\n",
    "    dt2_entropy = DecisionTreeClassifier(random_state=1,min_samples_leaf=i,criterion=\"entropy\")\n",
    "    print(\"Min sample leaf:\",i)\n",
    "    #call the function\n",
    "    dt2_entropy = create_model(dt2_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "561ddc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 274 1315]]\n"
     ]
    }
   ],
   "source": [
    "#We use min_samples_leaf=49 \n",
    "dt2_entropy = DecisionTreeClassifier(random_state=1,min_samples_leaf=49,criterion=\"entropy\")\n",
    "#call the function\n",
    "dt2_entropy = create_model(dt2_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2674c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here recall score is 83% which is less comapre to gini index \n",
    "#for now GINI Index is good compare to Entropy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d213c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.508748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.143871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.108639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.061645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.059954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.029745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.025663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>0.020506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day</td>\n",
       "      <td>0.014908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job</td>\n",
       "      <td>0.009614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.008122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.002651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education</td>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.508748\n",
       "1     contact  0.143871\n",
       "2       month  0.108639\n",
       "3       pdays  0.061645\n",
       "4     housing  0.059954\n",
       "5     balance  0.029745\n",
       "6    poutcome  0.025663\n",
       "7         age  0.020506\n",
       "8         day  0.014908\n",
       "9         job  0.009614\n",
       "10   campaign  0.008122\n",
       "11   previous  0.003227\n",
       "12       loan  0.002651\n",
       "13  education  0.001799\n",
       "14    marital  0.000906\n",
       "15    default  0.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check information gain of entropy:\n",
    "dict4 = {\"Input\":x.columns,\"IG\":dt2_entropy.feature_importances_}\n",
    "df6 = pd.DataFrame(dict4)\n",
    "df6.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "630712fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Applying the RandomForestTree of Boosting Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55150830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Random Forest Tree : It is Boostraping Ensembling Technique\n",
    "#It is work with Bagging classifier Boostraping Ensembling Tech.\n",
    "#In RandomForestTree : Train the dataset on multiple DecisionTree Alogrithm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b18c34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble means to train random dataset on multiple Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8cb15a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Decision Tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      1760\n",
      "           1       0.81      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1467  293]\n",
      " [ 301 1288]]\n",
      "No. of Decision Tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 243 1346]]\n",
      "No. of Decision Tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.82      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1452  308]\n",
      " [ 282 1307]]\n",
      "No. of Decision Tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.84      0.84      0.83      3349\n",
      "weighted avg       0.84      0.83      0.83      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 222 1367]]\n",
      "No. of Decision Tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1450  310]\n",
      " [ 271 1318]]\n",
      "No. of Decision Tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1422  338]\n",
      " [ 226 1363]]\n",
      "No. of Decision Tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84      1760\n",
      "           1       0.81      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1449  311]\n",
      " [ 258 1331]]\n",
      "No. of Decision Tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.84      0.83      3349\n",
      "weighted avg       0.84      0.83      0.83      3349\n",
      "\n",
      "[[1422  338]\n",
      " [ 219 1370]]\n",
      "No. of Decision Tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1448  312]\n",
      " [ 239 1350]]\n",
      "No. of Decision Tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 213 1376]]\n",
      "No. of Decision Tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 236 1353]]\n",
      "No. of Decision Tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 204 1385]]\n",
      "No. of Decision Tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 227 1362]]\n",
      "No. of Decision Tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.80      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 207 1382]]\n",
      "No. of Decision Tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 226 1363]]\n",
      "No. of Decision Tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 209 1380]]\n",
      "No. of Decision Tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 230 1359]]\n",
      "No. of Decision Tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.80      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 215 1374]]\n",
      "No. of Decision Tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 232 1357]]\n",
      "No. of Decision Tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1431  329]\n",
      " [ 209 1380]]\n",
      "No. of Decision Tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 227 1362]]\n",
      "No. of Decision Tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 206 1383]]\n",
      "No. of Decision Tree: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 229 1360]]\n",
      "No. of Decision Tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 208 1381]]\n",
      "No. of Decision Tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1443  317]\n",
      " [ 227 1362]]\n",
      "No. of Decision Tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 213 1376]]\n",
      "No. of Decision Tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 225 1364]]\n",
      "No. of Decision Tree: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 206 1383]]\n",
      "No. of Decision Tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 218 1371]]\n",
      "No. of Decision Tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 211 1378]]\n",
      "No. of Decision Tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 220 1369]]\n",
      "No. of Decision Tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 203 1386]]\n",
      "No. of Decision Tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 215 1374]]\n",
      "No. of Decision Tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 204 1385]]\n",
      "No. of Decision Tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1436  324]\n",
      " [ 213 1376]]\n",
      "No. of Decision Tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 202 1387]]\n",
      "No. of Decision Tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 207 1382]]\n",
      "No. of Decision Tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1431  329]\n",
      " [ 201 1388]]\n",
      "No. of Decision Tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 208 1381]]\n",
      "No. of Decision Tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 201 1388]]\n",
      "No. of Decision Tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 210 1379]]\n",
      "No. of Decision Tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 202 1387]]\n",
      "No. of Decision Tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 209 1380]]\n",
      "No. of Decision Tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 195 1394]]\n",
      "No. of Decision Tree: 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 206 1383]]\n",
      "No. of Decision Tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 194 1395]]\n",
      "No. of Decision Tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 203 1386]]\n",
      "No. of Decision Tree: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 199 1390]]\n",
      "No. of Decision Tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 205 1384]]\n",
      "No. of Decision Tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 199 1390]]\n",
      "No. of Decision Tree: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 205 1384]]\n",
      "No. of Decision Tree: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 196 1393]]\n",
      "No. of Decision Tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.85      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 202 1387]]\n",
      "No. of Decision Tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.85      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1435  325]\n",
      " [ 195 1394]]\n",
      "No. of Decision Tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.85      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 202 1387]]\n",
      "No. of Decision Tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1435  325]\n",
      " [ 193 1396]]\n",
      "No. of Decision Tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 200 1389]]\n",
      "No. of Decision Tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1436  324]\n",
      " [ 191 1398]]\n",
      "No. of Decision Tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.87      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 199 1390]]\n",
      "No. of Decision Tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 189 1400]]\n",
      "No. of Decision Tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 196 1393]]\n",
      "No. of Decision Tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1436  324]\n",
      " [ 190 1399]]\n",
      "No. of Decision Tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 197 1392]]\n",
      "No. of Decision Tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1435  325]\n",
      " [ 190 1399]]\n",
      "No. of Decision Tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 196 1393]]\n",
      "No. of Decision Tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1441  319]\n",
      " [ 188 1401]]\n",
      "No. of Decision Tree: 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 194 1395]]\n",
      "No. of Decision Tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 188 1401]]\n",
      "No. of Decision Tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1446  314]\n",
      " [ 193 1396]]\n",
      "No. of Decision Tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 185 1404]]\n",
      "No. of Decision Tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 193 1396]]\n",
      "No. of Decision Tree: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 188 1401]]\n",
      "No. of Decision Tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 192 1397]]\n",
      "No. of Decision Tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1438  322]\n",
      " [ 186 1403]]\n",
      "No. of Decision Tree: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 189 1400]]\n",
      "No. of Decision Tree: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1437  323]\n",
      " [ 185 1404]]\n",
      "No. of Decision Tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 187 1402]]\n",
      "No. of Decision Tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1435  325]\n",
      " [ 184 1405]]\n",
      "No. of Decision Tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 190 1399]]\n",
      "No. of Decision Tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1435  325]\n",
      " [ 186 1403]]\n",
      "No. of Decision Tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1440  320]\n",
      " [ 191 1398]]\n",
      "No. of Decision Tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1436  324]\n",
      " [ 187 1402]]\n",
      "No. of Decision Tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1439  321]\n",
      " [ 192 1397]]\n",
      "No. of Decision Tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 188 1401]]\n",
      "No. of Decision Tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1436  324]\n",
      " [ 193 1396]]\n",
      "No. of Decision Tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1426  334]\n",
      " [ 190 1399]]\n",
      "No. of Decision Tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1434  326]\n",
      " [ 193 1396]]\n",
      "No. of Decision Tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.85      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 190 1399]]\n",
      "No. of Decision Tree: 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.85      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1432  328]\n",
      " [ 194 1395]]\n",
      "No. of Decision Tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.85      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1427  333]\n",
      " [ 191 1398]]\n",
      "No. of Decision Tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.85      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "[[1434  326]\n",
      " [ 193 1396]]\n"
     ]
    }
   ],
   "source": [
    "#create object for RandomForestClassifier class\n",
    "for i in range(10,101):\n",
    "    rfc = RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Decision Tree:\",i)\n",
    "    \n",
    "    #call funtion\n",
    "    rfc = create_model(rfc)\n",
    "    \n",
    "#here n_estimators means take how many no. of decisiontree\n",
    "\n",
    "#n_estimators >= 10 but n_estimators <= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc5748b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      1760\n",
      "           1       0.81      0.88      0.84      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.85      0.84      0.84      3349\n",
      "\n",
      "[[1429  331]\n",
      " [ 196 1393]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=61,random_state=1)\n",
    "#By default gini index\n",
    "#call function\n",
    "rfc = create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f46e2e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
       "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'deposit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e97d831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.361433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.088253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.087126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month</td>\n",
       "      <td>0.083450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day</td>\n",
       "      <td>0.071436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.051406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>job</td>\n",
       "      <td>0.039788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.038709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.038642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.033713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.033217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education</td>\n",
       "      <td>0.022186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.019489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.019488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.010276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.361433\n",
       "1     balance  0.088253\n",
       "2         age  0.087126\n",
       "3       month  0.083450\n",
       "4         day  0.071436\n",
       "5       pdays  0.051406\n",
       "6         job  0.039788\n",
       "7     contact  0.038709\n",
       "8    poutcome  0.038642\n",
       "9     housing  0.033713\n",
       "10   campaign  0.033217\n",
       "11  education  0.022186\n",
       "12   previous  0.019489\n",
       "13    marital  0.019488\n",
       "14       loan  0.010276\n",
       "15    default  0.001388"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict5 = {\"Input\":x.columns , \"IG\":rfc.feature_importances_}\n",
    "#feature_importances_ inbuilt method of RandomForestClassifier class\n",
    "#To show information gain each input\n",
    "\n",
    "df6 = pd.DataFrame(dict5)\n",
    "df6.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f90635c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.84      0.71      1760\n",
      "           1       0.70      0.40      0.51      1589\n",
      "\n",
      "    accuracy                           0.63      3349\n",
      "   macro avg       0.66      0.62      0.61      3349\n",
      "weighted avg       0.65      0.63      0.62      3349\n",
      "\n",
      "[[1485  275]\n",
      " [ 948  641]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1760\n",
      "           1       0.74      0.74      0.74      1589\n",
      "\n",
      "    accuracy                           0.75      3349\n",
      "   macro avg       0.75      0.75      0.75      3349\n",
      "weighted avg       0.75      0.75      0.75      3349\n",
      "\n",
      "[[1351  409]\n",
      " [ 419 1170]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81      1760\n",
      "           1       0.79      0.78      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 349 1240]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1760\n",
      "           1       0.79      0.79      0.79      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1430  330]\n",
      " [ 336 1253]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1760\n",
      "           1       0.79      0.79      0.79      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1425  335]\n",
      " [ 330 1259]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1760\n",
      "           1       0.80      0.82      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1433  327]\n",
      " [ 289 1300]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1760\n",
      "           1       0.81      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1442  318]\n",
      " [ 265 1324]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84      1760\n",
      "           1       0.80      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 232 1357]]\n"
     ]
    }
   ],
   "source": [
    "#Apply pruning technique max_depth \n",
    "for i in range(1,9):\n",
    "    rfc1 = RandomForestClassifier(n_estimators=61,random_state=1,max_depth=i)\n",
    "    #by default gini index\n",
    "    #call function\n",
    "    print(\"Max Depth:\",i)\n",
    "    rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c112509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84      1760\n",
      "           1       0.80      0.85      0.83      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1428  332]\n",
      " [ 232 1357]]\n"
     ]
    }
   ],
   "source": [
    "rfc1 = RandomForestClassifier(n_estimators=61,random_state=1,max_depth=8)\n",
    "#By default gini index\n",
    "#call function\n",
    "rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04285233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.483505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.069499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.069024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month</td>\n",
       "      <td>0.065383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.063512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age</td>\n",
       "      <td>0.052272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.049891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.041654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.026522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.024869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.014794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job</td>\n",
       "      <td>0.013857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.010334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education</td>\n",
       "      <td>0.007755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.006509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.483505\n",
       "1       pdays  0.069499\n",
       "2    poutcome  0.069024\n",
       "3       month  0.065383\n",
       "4     contact  0.063512\n",
       "5         age  0.052272\n",
       "6     housing  0.049891\n",
       "7     balance  0.041654\n",
       "8    previous  0.026522\n",
       "9         day  0.024869\n",
       "10   campaign  0.014794\n",
       "11        job  0.013857\n",
       "12    marital  0.010334\n",
       "13  education  0.007755\n",
       "14       loan  0.006509\n",
       "15    default  0.000619"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict6 = {\"Input\":x.columns , \"IG\":rfc1.feature_importances_}\n",
    "\n",
    "df7 = pd.DataFrame(dict6)\n",
    "#sorting\n",
    "df7.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35e4a27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Sample Leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 237 1352]]\n",
      "Min Sample Leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1416  344]\n",
      " [ 239 1350]]\n",
      "Min Sample Leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1419  341]\n",
      " [ 237 1352]]\n",
      "Min Sample Leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 237 1352]]\n",
      "Min Sample Leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 247 1342]]\n",
      "Min Sample Leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 241 1348]]\n",
      "Min Sample Leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 242 1347]]\n",
      "Min Sample Leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1415  345]\n",
      " [ 242 1347]]\n",
      "Min Sample Leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1419  341]\n",
      " [ 248 1341]]\n",
      "Min Sample Leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1412  348]\n",
      " [ 244 1345]]\n",
      "Min Sample Leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 246 1343]]\n",
      "Min Sample Leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1411  349]\n",
      " [ 240 1349]]\n",
      "Min Sample Leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 243 1346]]\n",
      "Min Sample Leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.83      0.82      3349\n",
      "weighted avg       0.83      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 238 1351]]\n",
      "Min Sample Leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.82      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 239 1350]]\n",
      "Min Sample Leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 245 1344]]\n",
      "Min Sample Leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 252 1337]]\n",
      "Min Sample Leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 253 1336]]\n",
      "Min Sample Leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 252 1337]]\n",
      "Min Sample Leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 261 1328]]\n",
      "Min Sample Leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1421  339]\n",
      " [ 257 1332]]\n",
      "Min Sample Leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 245 1344]]\n",
      "Min Sample Leaf : 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 253 1336]]\n",
      "Min Sample Leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1417  343]\n",
      " [ 251 1338]]\n",
      "Min Sample Leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1415  345]\n",
      " [ 248 1341]]\n",
      "Min Sample Leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1418  342]\n",
      " [ 250 1339]]\n",
      "Min Sample Leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 252 1337]]\n",
      "Min Sample Leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1415  345]\n",
      " [ 253 1336]]\n",
      "Min Sample Leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 251 1338]]\n",
      "Min Sample Leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 254 1335]]\n",
      "Min Sample Leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 258 1331]]\n",
      "Min Sample Leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1419  341]\n",
      " [ 258 1331]]\n",
      "Min Sample Leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      1760\n",
      "           1       0.80      0.84      0.82      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1418  342]\n",
      " [ 257 1332]]\n",
      "Min Sample Leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1412  348]\n",
      " [ 266 1323]]\n",
      "Min Sample Leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 261 1328]]\n",
      "Min Sample Leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 261 1328]]\n",
      "Min Sample Leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 259 1330]]\n",
      "Min Sample Leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1406  354]\n",
      " [ 265 1324]]\n",
      "Min Sample Leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1413  347]\n",
      " [ 259 1330]]\n",
      "Min Sample Leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1411  349]\n",
      " [ 259 1330]]\n",
      "Min Sample Leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 259 1330]]\n",
      "Min Sample Leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 267 1322]]\n",
      "Min Sample Leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 268 1321]]\n",
      "Min Sample Leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 269 1320]]\n",
      "Min Sample Leaf : 89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1404  356]\n",
      " [ 265 1324]]\n",
      "Min Sample Leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 274 1315]]\n",
      "Min Sample Leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 275 1314]]\n",
      "Min Sample Leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 267 1322]]\n",
      "Min Sample Leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1410  350]\n",
      " [ 264 1325]]\n",
      "Min Sample Leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1404  356]\n",
      " [ 260 1329]]\n",
      "Min Sample Leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1406  354]\n",
      " [ 261 1328]]\n",
      "Min Sample Leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1405  355]\n",
      " [ 263 1326]]\n",
      "Min Sample Leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "[[1408  352]\n",
      " [ 265 1324]]\n",
      "Min Sample Leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1400  360]\n",
      " [ 262 1327]]\n",
      "Min Sample Leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1760\n",
      "           1       0.79      0.83      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1398  362]\n",
      " [ 263 1326]]\n",
      "Min Sample Leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      1760\n",
      "           1       0.79      0.84      0.81      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.82      0.81      3349\n",
      "weighted avg       0.82      0.81      0.81      3349\n",
      "\n",
      "[[1401  359]\n",
      " [ 262 1327]]\n"
     ]
    }
   ],
   "source": [
    "#Applying Purning technique min_samples_leaf\n",
    "#between 45 to 100 for that use for loop\n",
    "for i in range(45,101):\n",
    "    rfc2 = RandomForestClassifier(n_estimators=61,random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min Sample Leaf :\",i)\n",
    "    #call function\n",
    "    rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f766d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      1760\n",
      "           1       0.80      0.85      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "[[1419  341]\n",
      " [ 237 1352]]\n"
     ]
    }
   ],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=61,random_state=1,min_samples_leaf=47)\n",
    "#call function\n",
    "rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f155eb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.546932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.070974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.067098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.064304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.055431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>month</td>\n",
       "      <td>0.050217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>0.042567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.026714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.025256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>0.014090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.010398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.008431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>job</td>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.005589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>education</td>\n",
       "      <td>0.005420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.546932\n",
       "1    poutcome  0.070974\n",
       "2       pdays  0.067098\n",
       "3     contact  0.064304\n",
       "4     housing  0.055431\n",
       "5       month  0.050217\n",
       "6         age  0.042567\n",
       "7     balance  0.026714\n",
       "8    previous  0.025256\n",
       "9         day  0.014090\n",
       "10   campaign  0.010398\n",
       "11    marital  0.008431\n",
       "12        job  0.006578\n",
       "13       loan  0.005589\n",
       "14  education  0.005420\n",
       "15    default  0.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check information gain :\n",
    "dict7 = {\"Input\":x.columns,\"IG\":rfc2.feature_importances_}\n",
    "df8 = pd.DataFrame(dict7)\n",
    "df8.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b658ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get recall score 85% in RandomForestClassifier class\n",
    "#while using pruning technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "122e89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Ensembling Technique Boosting\n",
    "#1.Apply ADA Boost : Adaptor Boosting \n",
    "#call inbuilt class AdaBoostClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eecaa494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1760\n",
      "           1       0.66      0.81      0.73      1589\n",
      "\n",
      "    accuracy                           0.71      3349\n",
      "   macro avg       0.72      0.72      0.71      3349\n",
      "weighted avg       0.73      0.71      0.71      3349\n",
      "\n",
      "[[1092  668]\n",
      " [ 296 1293]]\n",
      "n_estimators : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      1760\n",
      "           1       0.72      0.72      0.72      1589\n",
      "\n",
      "    accuracy                           0.73      3349\n",
      "   macro avg       0.73      0.73      0.73      3349\n",
      "weighted avg       0.73      0.73      0.73      3349\n",
      "\n",
      "[[1313  447]\n",
      " [ 450 1139]]\n",
      "n_estimators : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1760\n",
      "           1       0.72      0.80      0.76      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.76      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1262  498]\n",
      " [ 310 1279]]\n",
      "n_estimators : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1760\n",
      "           1       0.72      0.74      0.73      1589\n",
      "\n",
      "    accuracy                           0.74      3349\n",
      "   macro avg       0.74      0.74      0.74      3349\n",
      "weighted avg       0.74      0.74      0.74      3349\n",
      "\n",
      "[[1298  462]\n",
      " [ 409 1180]]\n",
      "n_estimators : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1760\n",
      "           1       0.75      0.70      0.73      1589\n",
      "\n",
      "    accuracy                           0.75      3349\n",
      "   macro avg       0.75      0.75      0.75      3349\n",
      "weighted avg       0.75      0.75      0.75      3349\n",
      "\n",
      "[[1393  367]\n",
      " [ 475 1114]]\n",
      "n_estimators : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      1760\n",
      "           1       0.75      0.70      0.73      1589\n",
      "\n",
      "    accuracy                           0.75      3349\n",
      "   macro avg       0.75      0.75      0.75      3349\n",
      "weighted avg       0.75      0.75      0.75      3349\n",
      "\n",
      "[[1393  367]\n",
      " [ 475 1114]]\n",
      "n_estimators : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1760\n",
      "           1       0.75      0.72      0.74      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.75      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1385  375]\n",
      " [ 441 1148]]\n",
      "n_estimators : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      1760\n",
      "           1       0.75      0.73      0.74      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.76      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1382  378]\n",
      " [ 431 1158]]\n",
      "n_estimators : 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      1760\n",
      "           1       0.77      0.74      0.75      1589\n",
      "\n",
      "    accuracy                           0.77      3349\n",
      "   macro avg       0.77      0.77      0.77      3349\n",
      "weighted avg       0.77      0.77      0.77      3349\n",
      "\n",
      "[[1414  346]\n",
      " [ 421 1168]]\n",
      "n_estimators : 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      1760\n",
      "           1       0.78      0.77      0.77      1589\n",
      "\n",
      "    accuracy                           0.79      3349\n",
      "   macro avg       0.79      0.79      0.79      3349\n",
      "weighted avg       0.79      0.79      0.79      3349\n",
      "\n",
      "[[1409  351]\n",
      " [ 366 1223]]\n",
      "n_estimators : 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1760\n",
      "           1       0.76      0.79      0.78      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1369  391]\n",
      " [ 332 1257]]\n",
      "n_estimators : 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      1760\n",
      "           1       0.76      0.78      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1374  386]\n",
      " [ 350 1239]]\n",
      "n_estimators : 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      1760\n",
      "           1       0.77      0.77      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3349\n",
      "   macro avg       0.78      0.78      0.78      3349\n",
      "weighted avg       0.78      0.78      0.78      3349\n",
      "\n",
      "[[1383  377]\n",
      " [ 358 1231]]\n"
     ]
    }
   ],
   "source": [
    "#Create object for AdaBoostClassifier class \n",
    "#Ada Boost consist of decision stump (means one root node and two leaf nodes)\n",
    "#leaf node maens no any child \n",
    "#ada boost consist of n_estimators between 1 to 13\n",
    "#so we apply for loop to find best n_estimators\n",
    "for i in range(1,14):\n",
    "    ada = AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"n_estimators :\",i)\n",
    "    #call function\n",
    "    ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd89599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1760\n",
      "           1       0.72      0.80      0.76      1589\n",
      "\n",
      "    accuracy                           0.76      3349\n",
      "   macro avg       0.76      0.76      0.76      3349\n",
      "weighted avg       0.76      0.76      0.76      3349\n",
      "\n",
      "[[1262  498]\n",
      " [ 310 1279]]\n"
     ]
    }
   ],
   "source": [
    "#From above for loop n_estimators=3 is best recall score\n",
    "ada = AdaBoostClassifier(n_estimators=3,random_state=1)\n",
    "#call function\n",
    "ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35ab7570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contact</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>job</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marital</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>education</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>default</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>housing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>campaign</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pdays</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>previous</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poutcome</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Input        IG\n",
       "0    duration  0.666667\n",
       "1     contact  0.333333\n",
       "2         age  0.000000\n",
       "3         job  0.000000\n",
       "4     marital  0.000000\n",
       "5   education  0.000000\n",
       "6     default  0.000000\n",
       "7     balance  0.000000\n",
       "8     housing  0.000000\n",
       "9        loan  0.000000\n",
       "10        day  0.000000\n",
       "11      month  0.000000\n",
       "12   campaign  0.000000\n",
       "13      pdays  0.000000\n",
       "14   previous  0.000000\n",
       "15   poutcome  0.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create information gain\n",
    "dict8 = {\"Input\":x.columns,\"IG\":ada.feature_importances_}\n",
    "df9 = pd.DataFrame(dict8)\n",
    "df9.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67260d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply LinearSVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4462506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object of LinearSVC class\n",
    "svc = LinearSVC(random_state=1)   #Hard margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10e67bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.79      0.77      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1444  316]\n",
      " [ 364 1225]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "svc = create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "248d07c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      1760\n",
      "           1       0.80      0.77      0.78      1589\n",
      "\n",
      "    accuracy                           0.80      3349\n",
      "   macro avg       0.80      0.80      0.80      3349\n",
      "weighted avg       0.80      0.80      0.80      3349\n",
      "\n",
      "[[1445  315]\n",
      " [ 364 1225]]\n"
     ]
    }
   ],
   "source": [
    "#got recall for 1 : 77% means it is good but not best\n",
    "#suppose outlier in our dataset means model overfitted\n",
    "#So reduce the overfit of model or remove outlier from given dataset \n",
    "#add some external error during training error means soft margin\n",
    "#Means again create the object of class LinearSVC and passing parameter \n",
    "#C means error parameter , the value of C can be <=1\n",
    "\n",
    "svc1 = LinearSVC(random_state=1,C=0.9) #soft margin\n",
    "\n",
    "#call function\n",
    "svc1 = create_model(svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8922c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be444fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f8f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b147e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
