{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d735f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the labraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9328c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.127   47        1  \n",
       "1                     0.233   23        0  \n",
       "2                     0.630   31        1  \n",
       "3                     0.365   24        1  \n",
       "4                     0.536   21        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the dataset\n",
    "df = pd.read_csv(\"kaggle_diabetes.csv\")\n",
    "\n",
    "#To show first 5 record\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84d78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delecting unwanted column from our dataset\n",
    "df.drop(\"Age\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf7c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3e2127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross check with datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ad8190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the ducpicated value in our dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26db9200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f003be23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the null value \n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa96b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1316\n",
      "1     684\n",
      "Name: Outcome, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To check the dataset is balance or unbalance\n",
    "#Here our target is Outcome \n",
    "#Condition: if Outcome is 1 the person has the diabetes or if 0 the person has no diabetes\n",
    "f = df[\"Outcome\"].value_counts()\n",
    "print(f)\n",
    "\n",
    "sb.countplot(data=df,x=\"Outcome\")\n",
    "plt.yticks(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e525ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The given dataset is balance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8456b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the input and output\n",
    "x = df.drop(\"Outcome\",axis=1)   #input\n",
    "y = df[\"Outcome\"]   #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e16a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  \n",
       "0                     0.127  \n",
       "1                     0.233  \n",
       "2                     0.630  \n",
       "3                     0.365  \n",
       "4                     0.536  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f08d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into 70-30 % by train test split class\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6514f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400, 7), (600, 7))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896d5cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400,), (600,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d84c5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Standard Scaler on our dataset to convert into a numpy array\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bb6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object for StandardScaler class\n",
    "ss = StandardScaler()\n",
    "\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffabc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user define function\n",
    "def create_model(model):\n",
    "    model.fit(x_train,y_train) #train the model with 70% data\n",
    "    y_pred = model.predict(x_test)  #model test with 30% data\n",
    "    \n",
    "    #generate Report\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48106a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the class\n",
    "from sklearn.metrics import classification_report , confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5492f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Performing Base Model means Linear regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c582b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       404\n",
      "           1       0.71      0.60      0.65       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 78 118]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for LinearRegression class\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#call the function\n",
    "lr = create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71cf6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Classification Model : Decision Forest Classification\n",
    "#call the inbuilt class\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "034a24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.94      0.94      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.95      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[392  12]\n",
      " [ 12 184]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for DecisionTreeClassifier class\n",
    "dtc = DecisionTreeClassifier(random_state=1)  #by default GINI Index\n",
    "\n",
    "#call function\n",
    "dtc = create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4033e89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.341456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.215926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.143296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.088965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.088803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.080236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.041317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.341456\n",
       "1                       BMI  0.215926\n",
       "2  DiabetesPedigreeFunction  0.143296\n",
       "3               Pregnancies  0.088965\n",
       "4             BloodPressure  0.088803\n",
       "5                   Insulin  0.080236\n",
       "6             SkinThickness  0.041317"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict1 = {\"Input\":x.columns,\"IG\":dtc.feature_importances_}\n",
    "df2 = pd.DataFrame(dict1)\n",
    "df2.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1002a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAADnCAYAAAC5W1UtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAByWUlEQVR4nO2dd5hjR5X2f6Ucu1udw3Sanug0HqeZccAmLMnGSzAZFrBhid+Cydl4Yb0sC5jMLosxyQGTg7FNMA4TnMdhHCeHzjkqq74/6qpb3bqSrlJrwn2fR0+rr+pWnXOq6ty6VXXeElJKTJgwYcLE8sJSaQFMmDBh4kSE6XxNmDBhogIwna8JEyZMVACm8zVhwoSJCsB0viZMmDBRAZjO14QJEyYqANP5mjBhwkQFYDpfEyZMmKgATOdrwoQJExWA6XxNmDBhogIwna+JYxZup2NACCGNfNxOx0Cl5TVhIhXC5HYwcaxCCCFv+85ncDnsSCkJR6I01wcIhsJIQACTM3N0tDRw8mVXIqUUlZbZhIkkzJGviWMSQggrwPmnr+PZg31EYnGqfR7GJmcIR2OEI1Gq/V7O37iejub6SotrwkQabJUWwISJbBBC+IA1wLoln1UA2x97Fp/bhZSSydkgazpaiMXjjE5Mc6h/GCklnS0NybweAp5Z8tkjpQwtv2YmTnSY0w4mKg4hhABaWexc12p/64HdpDvN54CZ6a0/M1SG//y3AmxJyTf56QaO6OT/jJRypBT6mTChB3Pka2LZIIRwokasS0exa4E54FkWnN+ftb+HpJTxDPlxaGCE3qExfG4ndTV+eofGsFgstDfV8dzBPqxWK1tOWwOAlPI+4L4lediBlSmynAdcAawXQsRY7JCT8u2XUsZKZhgTJyTMka+JkkMIUUe6g10HtAMHSB9lPiulHM+3HLfTMRCKRJuMpHU57IPBcKTZaN7aaLwRfT1agL3o6zGVlxImTliYztdEQRBC2IAu9EexdnRe44F9UspIJeQtJYQQHmA16VMYa4EJ9HXvlVImKiGviaMTpvM1kRVCCD/pTmYd0AMMsPh1PPkZlCdgwxJCWIAV6I+Wq1Dz1Eud8m4pZbAiApuoKEznayL5ip10GksdbQC14PU06U5jriICH4MQQlSTbtv1qAW/PvRHy8Mn4kPsRIHpfE8gCCFcqNdlvamCafQdwGHzdbl80KZvukmvk/VaEr0Fv31SyujyS2uilDCd73EGbRTbgP4otg3Yh/5C0WRFBDahC60e69GfwmgD9qNfjxOVkNdE/jCd7zEKbcSUukUq9QP6o9j95ojp2If2BqO3ZW8di99gUufiD5lvMEcXTOd7lEObK0ydHkh+Xwn0ojP6wZwrPCGhjZbb0HfKtegv+D1nzt1XBqbzrTC0DiNQe2D1Oo2f9N0EyQWvUCVkNnHsQdu1kilMexD90fKA+RAvH0znWyK4HbaBUDRubMO/3ToYjMSaNcebACLAMPqjWHN/qImyQSMo6kJ/EbYGGJFStibTO13ugUg4ZKidO5yuwXAo2FxqmY8XmM63RBBCyOHr32MobcM7/mee3lAIcTHwuJTycDnlM2EiXwghTgWqpZRbU67JP++eNXT/y1d7TRrPLDC5HUqMm7c+S2djFX6XnVA0jgC8Ljs9TdXYbda09FLKW5dfShMmckNK+USm3/72m5/T3N6Nx+cnEgohLBaklAQammhq61hOMY9ZmHy+JYAQwp383tVYxchUkKlghEgsTnu9H6/TziP7h9i5b6iSYpowURCEEO1CiPcIIf4E8ORD23F5fEgpmZ2eoqm9k7omNTMxdOTg0ntfqdGCmlgCc+RbBIQQq4D3AG9LXtu8pkU3bXu9f+m9XwX+R0q5p4wimjCRN7R54M3AxdqnDbgN+Dlw8clnnat7X31zq97lDwA/E0JsB24FbpVS7i2D2McczDnfPKE1zIuB9wFnAtcD/+uyW7cZXXBz2q0j4Wj8euAdwMPA91CNUpc60YSJckMIEQBeAlwCvBS1jfFW4E/A/cm2aXc4RmPRaK2RPJMLbkKIKuCfUP3m5cB4St7bTtS956bzNQghRBOK5/XdqFj87wG/zLbdSwgRWEqVmHpNm654LcqRtwD/C1wnpRwsjxYmTChoO23Wo5ztxcBG4G6UU/yzlPKQwXyytnGd9BbUoOVirewe4C9aubdJKYcL0+jYg+l8s0BroOejnONLgV8B35dSPlKGss4A3gtchnrF+x5qVGBWkImSQIuMu4gFx2dBjT5vBf5RCXY1IUQL8DJNnhcCT2ny3Ao8ejy3f9P56kDbkP4WlNN1oBzhTwsh/C6g7ABqDvm9QFgr+wYp5XS5yzZx/EEI0cbC3O3zgcdRDvdPwJNHk3PTTjp5HgsPBxfqRJM/AX+XUhrb43aMwHS+KRBCnIJyem8E7gS+D9xZiQaqjbpfgHoAPB+4CTXq3rXcspg4dqCtSZzNwnRCB3A7aiR5h5RytILiGYbW/tew4IjPBraysGi3v4LilQQnvPMVQjiAV6Gc3GrgB8D/SSl7KypYCoQQK4B3aZ/dqNHwb4+HUyFMFA8hRA3wYhYWywZZmE6473g4b07jOHkxyhm/DBhhQcftx6KOJ6zzFUK8AtVYL0URhX8P+P3RvPKqHfb4z6gHxXrgh8APzOi4EwvaqHAdC6PCM4B7WRgVHsxy+zEPbdHubBamU7qBO1D6336snDp9IjvfJ1H7nF8ppXy60vLkCyHESag9xm9GnTaxxtwzfPxCWyy7kAWHa2dh5HfnicxMJoRoRW1huwQ1RbeLha1sTxxN89qpOGGd7/EC7aTgHwAflFIeqbQ8JkoLIcTrgP/T/t3FgsM9ap1KJaEt2i19SCWAy6WUd1ZStqU4ppyvy24dCMcShgIZcsFpswyGovHjknHJ7bQPhCIxg0eq2waD4ehxaYejDW63eyAUMsYI5nK5BoPBYLMQ4sWoN5x/PVZep48WaNMza1GReV+WUv4KwOZ0D8QjxurB6nANxsLlYWY7ppyvEEJ+8w2nsSKgqBQEArfdQjQh2T88y4padd3rtDEbjmG1CKSERr+TYDSOlBCJKXbGi7+9/bhlXBJCyIk/fYXr/ryDkzqbaazxMReO0tEUYPeRYSLROC6HjTPWtFNzycePWzscbRBCyO9846ucevJJNDU2Mjc3R1dnB888t5tIJEJNdTWnnnIyAFZvwKyXMkEIIf/tthEe/9OPqO86CU+ggWg4SKCth4m+fUTmZmhaewZWm51vvay+bPVwzHE7vO6sFWnXbnnwCB11HvwuG6FoHLtF2WpNk4+Ax7HcIh41cDvtSAlz4SihSJQ9R4bxuhxs6GnQZVgzUX68911X8JOf34SUkiq/n6effQ6LxUIiIWlsaKi0eCcU7E4PEkk0HCQWDjGy/ylikRD13SdhtdnLXv5xwWrWWe9hZCbMVDBGJCZp8DvprvfyTP8MjxycqLR4FUN3cx3DkzNMzYUUw1pjgGqvm/ufPsD2Xcf8NsljElu378Dn8yKlZHJqiu7OTtpaW7BYBAcOGYroNVEiVLd0EZwYITI7RSIWoaqpnZrWlUwP9zK057Gyl3/MjXz1sKlbn+ejpdq1zJIcXdhycrfu9db66mWW5MSGxgvyHoDzz92im6atVZcRzEQZ0XrKZt3rvnp9ZsJS45h3vtv3jtIe8NA/GcTrtFHrddA/EcJpt1DlsjM4FaIt4D4hHLFG1PNRgK1P7KWjqZa+kUm8Lgd1VV76RicJRaI0BfxMzoaIxRPJ+6rNo+NLDyHE6cAHgVcCtwAcPHSII719+Lxe6uvrGB0dIxyJUOX3MzE5SSwW47wtm5P3/wX4BmrvqnmUVAlx5PFtVDV1MDPSh93txV1Vx8xoP4EVqxjZtwuHtwp3VV1ZZTimFtzM3Q760FZ1LwP+G3jQ5bBdFIrE6o3c67TbguFobBL4LPBjk9ayOGjhva8APoQ6nPK7qIjJkXx3O4RCoY8BVwJe4FvAT6SUM+WR/MSBuduhCGgN/NvAJuCl2WjohBDdKMq6nwP/frztjdRGV98EqlF7fe8uII8ztTw8Wh73llTIEwBa+OvlwP8DhlAj1l8XGzGZwqz3QRQj2Y+B70gpDxSTr4kFCCH6UMEZjwKB5ToV/JhbcNO4GG4ATgKen4v/UyPgOB/F3/BNLTTxmIcQolEI8b8o0pQbgTMLcbwAUsqHgQuA/wJuEELcLIQwD+IyACHEKiHEN4H9qMHAm6SUm6WUN5ciVF0q3CulvAw4S7v8sBDi10KICzTnbKJAaPPxbuA5FG/KKctV9jHliIQQXuCPKKq5l0opp4zcp5GTX4QijP6ZxpFwTEII4RBCfBh4EpgF1kkp/7fY6QKtk/8CxRnwNPCIEOJqzeYmUiAUXiiE+AOwA5gDTpNSvkFKeV+5ypVSHpBSfhToRLHuXQc8JIT4Fy2yy0T+OAN4RHsj3onyEcuCY8b5CiFqgb+hTpG4LN9XAynlBOqYlGrgd0IIT8mFLDOEEC8HngBeBFwgpfywplfJIKWck1JejWqUa4CnhRBvNEdYakFTCHEFihP326hQ304p5aeWM7RbSjkjpfwu6kH5eRT39AEhxOeFEI3LJcdxggtQ9QngA65etpKllEf9B9XIJHAtYCkyLztq5Vmi5ncqrp8BmV+EOt3iGeDly1z2Bahz5raiFpJEpe1RAfu3Al9CzeXeijqP7KiyA+p1+Qeo89GuB06vtEzHwgd1YMEfte8XAv+1XGUfEwtu2inBXwTeKkvA26m9Sv8MuEIuw+kUxUAI8XzUK+anga/JCnD4agucb0O95r5XSvk/yy1DJaAdeT6Omt65AfiWlPLZykqVHUKIehTv8/tRc5hbgWtkBY4IOhag+ZaDsgJUsseE8z2Rob3uB6SUY0eBLAFgUp4ge061fdM3AB+VUu6rtDz5QFvXuAy1GPt+KeX3KiySiSUwna8JEyZMVAAVXXBzWC2jQghp9OOyWwdKVrbdmlfZbqe96LJddutAPmWWWudSwmG3Gbaf2+moqA4OW5517Si+ro9WOF1uQ23Q4XAel0e4u+yWRfrbHC5DbcLmdJe8TVR05CuEkH3XPN9w+tZP/wNZIno3IYQc/90XDacPvPJzRZcthJB9//mCvO5p/dSdJdO5lBBCyJn7f2EorW/T6yuqgxBCjv3qs4bT1172paPS5qWAEELedSD39O9FXe7j0gZCCHntq3roDLjwOa28+PuP854/5X7O/M8lDSW3x1HD7XDLI/10Btz4NFrIaFzisAkafU5WBMrLy3DTnTvpbArg9zgJRWIkN1WtWdFAlac8Zd/ycD+dtW58LiuhaIJoPIGUcEqrH7/rqKkWQ7jh1rvpam2kyusmGI5gsVgIhiOc3NNBbbWv0uItwk13PUZXo6rrYCSKQFDtdeH3OGgO+Cst3rLh9l/9nNaOLjy+KsKhIBaLhXAoxMp1J1NVo09UdbygK+BieDbK0nHns3+/maqmTuweP/FICITA4aki0L66LHIcFb38/gMTeB1WJDAditFT7yGWkAzPRBiaCZfd+XY11zI8MUOyLla31ROLJ9jTO8Kp3S1l4b7trHMzMhNBouI9euq9xBKSQ+NBgpEEZ3UeG8xj2x99Bq/bhUQyOTvH6o5W4vEEg6MT7D7Ux6ZT11RaxHnc9/QhvC4HEsnUXIhVrXXE4gmGJmbpaqqptHjLhscf3Ibb60VKmJ2eon3lauLxGEO9hzmyfw8nbTyn0iKWFed0Vi36v//J+whODONv6kAi8QQaScTjhKZGicwZiuMqCEeF893UVaN7vaV6eYJ2tpzUqXu9ta5K93opUGmdi0FqwMW5p6/TTdPaePSNnjav14+YLmc9H4047ezzdK83NLctsyTLD7uFsbardixqnC0nV4ZasqJzvvmylJWSiSyfc86gNGedFcLKdrSxrwkh1gDfcTrszw9HooYe3k6HPRGORF8tpfx9mcXThdthHwhF86hru20wGDk+z7VzutwDkXBuRi+7wzkcCYeO+2g5m9M1GI+Ec+ppsTuH45HS2qOiux00p9KBihzarE1o12p/LcDvgK8nr5XSCQXD0WatnH8DtgO2JeVfhYoqq5VSilIcMhmKxpullCL5AR4CXgbUAu8FfpUqQ6l1LgZaaO2/o2x1ezgSdafqslTu1GvhSPRFwJeFEH8QQnQtt+zBSHSp3T+Gomi8D3jRUvmPV8cLEA4Fm4F3o3gMnEva/AZgBFgVjYTXVlDMZUM8Ej4VOAC8cWk7QPmgm4CbE9Ey2KPCoX1W4C7gUxl+rwMOo0h0ylH+alRjW6Pzmx0VVntFmco+TdPNqv1fDUwADZWskwyyvgzYA/wSWFFgHg7gU5q9Pw04KqjPjcDbUQ74Y5W27zLrvhYYBtZn+P1DKLIgW6VlXQZbOFERgF/MksYN3A98tuTlV1j5z6JCZ61Z0lyEItNpKnHZVs3wH8yS5lStoXaWQfdvLK104KfAlZWskyXyrAB+pTnekjwAgS4UM93TwAsqpNfT2sPv7cCNlbbzMurtQL1tvTdLGgtwB/CFSstbZlsI4EfAr8nBFwO0aAOlV5dUhgoqvwUYANoMpP0P1BRAUaQ6S/L8CHC3AcN/CsWmVjIiFaAeGANWLrl+EfBUpUcdqFH/R7RR6hcAd4nzF8A/AwdRJPfNy6hbExDSdNwAPF1JWy9zvf6n9uDL2pY1ZzMAnFtpmctoi4+gyNO9BtOfqQ3ETi+ZDBVSfC0QB15jML0dRVb9YInKfzOQWOr8MqS1aQ3xrhLqfzWKQnfpdQuKbe3tlagXTYbzUBR7fwFWl7ksL/BlrVF/gCxvQCUs8y2ajQXq5A5Jhlfw4+mDIsoPAo0G079W6yOrKi17GWzxY23w05Hnfa8FZijRG1ulFtxsqFeb3xpJLBXj0MdQT6pSYBD4ujRAliIVi9r7UXPTpcLVqDnepWUlUGTON5awLEMQQliFEHOo17AvAS+RUu4uZ5lSylkp5SdRI/43ADEhxMoyl/lzwCVVbwqiFhDnylnmUYJ+4D+llEMG0/8G+DPqIXW8oRH4HynloXxuklL+EtgFnFwKIUxiHRMACCFswB+Af5NS7qlA+U7gGtQ8+MRyl2/CxHLDdL4mTJgwUQGUfNqhHMxdbperkDzjpWIMc7lzM0G5bJa85NPNw+nMzrblchmS1+20520vxT5WOTYvh0G2LUN2dNhz1r2u/g7bMctmZtR+Dpdxdi6jffloYt6zOY3ZoRiWMrcBf+B2586/5CNfIYT87btORwhorXJyZCKExSKoctlwWAXBaAKnzUI4lmAqFKPR7+CCax9EZmEMEkLIv//yOoQQtDU3cqi3H6vVSrXfh9PhYC4YQkpJOBIhFI7Q0dbCugsu4e8fPo8qtx2rRTAwGaLe52RkJozFIojHJRd/e0fWclPL//xXvs2a9adQ19BIKDiHlBIhBFabDZvdzss3n8I3X72GFTXO5D24bBaiCcn+0SDt2nWvw8psJI7FIkBCg99BMBJHAi/+3k7+/svraKqvYy4Yoqernb0HDgMQCod53qveZljeu751JcFwFCEErfXVHB4ax2qxUOV14bTbmAtH6GiqZffhIUKRKH6Piwv/39cN5V8OCCHkp6+7TfsODqebWCzK4KG91Leq8G+Xx0tobhaLRa1LVtc1EQ4FaWjtoP/AbmwOJ3PTk1xzxcv43/e/jOaAD4uAhASrReB3O5iYDdNRX8ULv/ArxiYmM8tjdw4mIqFjJthCCCHf+blr6Vh9MjX1jYSDQexOJ9FwmEQijtvrp6Wzh9ee7DNcx0II+fcrz6PKbZvvQ83VLg6MzuG0WbBaBKe1VdH68Tsq1m6WQgghX/Kl32O1O5FI4pEwntpmYuE5rA4X8UiIyOwUf/ncKwuWWQghd953DzXV1VitFnr7+mlqbGRwaIhoNIbDYWfzhf+UM/+ycDts6lJrSbc8MkBnrUs5nHCciXgCCaxq8NDgc+SV53lnq0NFf/arP9Ld0YbP42Fmdm7e8Z6z8dS0e3b1TtFR58HvspGQkulQlGA0zvoWPwFPfuW/8R3v5nc3/xQpJT6/n3A4jMViQYbD1DeqaM3XbtSP2tw/GsQiBD6nlVAsgRACu0XQVuOiyb9Yjn0HjyClpMrnY9czu1UZGfTLhtNXt89/v/GvD9LVUofX7WA2GCYYjhAMRwkHYpy1Tp/XohJYf9b5adcGD+3FYhG4vFVEw0EcThdSSmrqm6hvXeBq6Dn1rEX3vebcBc6Jm+95ks7GaqQEp83K0OQsYxOTbLmuN6MsO65oyysM/GjAS97wLu763Q2AxO2tYnZqAiEsRMJBAg2FPUdOavVzy0O9dNS68bts9E2EqHbZmQpF6a73II7Cc1WbTt7C3jtvxtfchcNbRXh6DIQgHg3jrmmktrv40+F3PvY4K7u6qKryk0gkGBwaIhgMsW7NapqajEUhl41Y5/4Dk4qpTGpMZQ0eYnHJgbEgh8dDeTvfJFZ2rmBoZCy59YM1K7uIxePsPXiYns72RWk76z0MT0dIDu47ap0EvA4OjQXxOfNT/eH7tuHx+pBSMj01RfeqNcTjMcZHR2hdoU/YAnD/wckFxrZwnJ56N7GEpG8yTO9EKM35ZtOvEOzYtQ+v24GUkqnZEKtXNBKLxxmamOHQ4BiNRzmNYuOKbqbGhuft0dK1hngsxsRwPzUNLdjs9px5dDXVMDw5N98OVrUGABh96Fbs/joAXM09yESM2Mw43vaTyqNMmfH0w9txebxIKZmbmaS1azXxeJyR/sNMjY8U5IDv3z+OR2u/U6EYqxoU+55E0uA7OkmgBp+6D5vbC1ISnZumqq0HGY8zO3yEmaHD+Brbc2eSAz3d3QwODc23y7WrVxGLxxgYGqKxscFQHmVzvsnR71IUy9qVHAEbkqFbn1mrpTp/isozN+szQTW1ZGeC2pSBGrKlSt8O+ehnBFtO0d+51VpfU9JyyoW1Z5yre722qdVwHpvX6teRr2sD4fF+rC4PMhEjMtqLsDsJj/cXJGulsf5MfVvV5WGrpdjUHdC9XkgfWi40naTPUuapKx1L2fnn6pfR1mrc1mVzvjv2T9Be46JvKozXYaXWY6d/KgxAlcvG6GyEjoA7L2d8z30P07mihd6BIXweD3W1NRw80ofDbqelqYG25sXD/cNjQfonQ3idVmq9DgYnQzRUOTk4Ose5PXV56fPAtnto6+hksK8Xj9dLoK6eg/v20rmyh4mx0cw2CLjom9Rs4LUzE44zMhOhPeDCahFpTvjgkb6M+uWLrY/voaOplr6RSbxuB3VVXobGp0kkJPU1Pg4NjrGytf6odcRPP7SVhtYOxgZ7cXp8+GvqGO7dT1N7DwOH9tC4YmVOJ7zt6SN01FfRNzaN1+Wgzu+mb2yahtoaHvnEpoz3CbtzsNT6lBvDfYcYHejF5fHhD9QxNthLoKGF4OwUoblZapvyp4zcvneM9lo3/RML/ejQWJCuOjcHR4Ock8E5VxIDu7bja2xnbrQPm8uLq6qO2dE+atrXMjvSRyw0W3QZBw8d5khvHz6fl/q6WiYmpuhob6O3rx+3220sk1JHjzhtlgFU1JDhj9NmGciWp8vpLCTPeLHlzuukdhlkz8sq8pJPNw+HI+vvLqfTkLwutWqfd/kuh81Q/uX42J25bWzYjnZbzrrX1d9urZj+JbDfoBEd7U6XYR2N9mWj/ajcH8ButTuDRmS22BwThZbjMuAPXK7cdi63MX4MfC7lfwcqnn9TkflegKIDfCOKhjFb2npgEhU59lSR5f4HKjIu+f+dwOsM3vu/qBDaW4FX5kj7IeC7wFfJwPhmoLxmFFXem7Ok+RSKWtBfznZQpM3rUWxv1dr/LwYeLiCfN6Citj4KfKvSepXYRjbgduDbWdJ8EsXSZ4jLQOf+XcAZWl0YClFeZhu4UbwVfwI8OdKegYr4u7zIMlN9y5P53l+28GIhRDfwCuA7yWtSygjw38Bnisx+I8pp7EQZ0kjaJ4EuIYSnkAKFEFbgbSgmpCSuAy43mEWqzLkmdvPRLw1CCC+qEV4npbwhS9Ivo1iufiFUhNvRiLcAf5RSJveF/Q2oF0Kcnmc++dj/WMM3UGHAV2ZJ81/AE8BPhRB59XshhBvoQfWhncDpBUlZJgghalB0BZPAq6SUWcPFpZSPABcCnxdCfLSIojeiKA+eBLrz9S3l5Hb4OPADKeX4kuvXAWcLIU4rIu9kR9oNNGjGz5pWc/zPoKgEC8FLgD4p5a6Ua79B6ZJ5uwMghLADpwCPYazzn6Gle8RA2qVlWVHcEE+gOBoyQqrH9/tQ9JrfFkfZviFNnitQbQYAqfgvfozxh14SG1H23AlsyNcBHa0QQnwAeD7qDSyWKZ1W1+9G8RoYP7Zb4TTgGSllmAIHBOWCEKIZxbuyE/gXqXhgckJK+RxwPnC5EOLLBbb9M4BHNN+SpCk1jjK9AryULAxKqFMiDlEgTSNqXuVy7fv9wCVZ0v4BeJv2fQD4R4FljgFX6VzfAezKce8mYI/2/QWa/Lpk4kCVZjsnyinOZrKjzr024Nuo0aFhsnKtzMdRnbJk1JklaEcfBaZZQvsJrAFiGGCl09JbgVGgNaX9vKHS+pXAPm/T2rQhO2j31AN7gY/kcc/HgZ9o39+KehM5GvTvRg3APleEL6nTfMj/kSer3hLfcj3wibzuL5NRPgI8nuX3k4HxIgz272hzV6hXjXuypJXAu7Tvl1IgKTjaiEnn+j8D38hx741AQvtuQ7FLZUr7TrSBSor8hk5bQJGxS6CmAP26tHvfWo42UaDNPwTcpHPdgnqLOMlgPls03dza///DMU4jqT2cJQXQj6LWTGQe9htGo3MF3pHaPiuo/ytQlJfvK0FePtQgKpaPT1riW3YAo/mUe8wT6wghGoC4lHIsw+9rgN2ygopqc7ABKeURA2ktqJHMHu3/lcBBKWXcwL1rUedyPV6gnJ1Ar8zy+nqsQgixRqpXzeMGQohWKWVfofcC/Ub6hTatNiKlnNNez1dX2pZCiAuBy1AsfEX3bSHECtR5ka83ml+qb9HmxRtkHjSVx7zzNWHChIljEUflooMQwpJr9V0IkTU+uRR5FJtvuWQoB44lWY9XLEcdmPV8FKHQeRK7RYxidNP7kk3YmYIAhNVmKD/QD2pwWoW0Wa2G80i735753nxks1mMB1wImzOnfjab8bKTHyObvF32woIxdMuzFx6gYbfbDbUll8s1YLHnDrgRdud8kIXTVlh7WM6AC6vNNlGqegCkY0kghRGb5WqTRoKInDZRtM0sNmNtAZA2h/GAEUNzsNbMZRvpp/napeBpByGE7PvSBYbStn72XmQKvZoQQo7/Ln23S+CVn+Mzd+pO3abhP15QS+/VW7jl0SE6Ay58Tisv/r6a6gwdeMRQHkvh6jqD0Zv0t/3VvfGrvOnXxiJOb3xNEwNff4WhtM0f/iNbrutlaNstuBo6sbp9JCIhdl1zKde+qofOgItX/+hJErGIYT0ALDbHIpvrQQghR2/6WF75ZkLdG/87Z3nZ5IjP6Idop8LqUyHhL/hJ9mnOO9/WOm/TvT+6kpGffCBvmerf9p2C9ckXQgj5QG+oZPmd0+ZK62/Pz2GzVPzjba30XH5tWntc2t9C0QTRuGRzVxUAbVcZo2jNBiGE/NI944bSfvZ5gZLWkRBCvuImfRreP76xOWM/LdQuRW+sv+WRQTprXfN0idGYcubd9e40xq5U3HTnTjqbAvg9TkKRGNl22T1+x03UtHTh9PqJhYMkEz9wcCqFOS37elSSirLK5yMYCmWlarzp7l10NdXgdzsIRmJZafP2/eMX+Jo6sXv8xCNBch159YsHD9NZ58HvtBGKJgCY2v0AVqdiYYrPTeNq7gGgK+BieDZ92+JPfvpTVnavpKrKTzAYQgjBpk3nZC03H6Trr66vqKuiOeArWTlL8ZMbbpqn6QsGg1gslow0ff1bb8Gd0gkSsSggCazbAqTYdAlu3vo0nQ3V+N2ORe2up7mGGu/RRxbzp1t+RltnN15fFeGQskk4FKRj5Wrqm4onikna0eb2EY+EkDHV3lyNXUQnhyFlcLa0v/XUu4glJA8dnub01tK2i0duu4na1k6tz4dACGKRMA0dq/HVGqNsLAaH7/4FnqZObG4/iYh6MGbqp5ns8uTALCc1ZY67KMr53n9gEq8zpdAGRZfYPxlm38hcVufb1VzL8MQMyapd3VafMW2gtZvZ8aH5hlDbvgqAczqrDMuaDxVld1MNQ5Nz82lXteizowH4mrsITSw0Un9bT8a09+8bna+kqVCMVY2qwVat1necevpt3boNn09RW05OTrF27RpisRh79+5l5cqVJeFXVfrPLtI/lkgwMjXHdDDC6tbM9igUW7ffh8/rXdBLo+gbGR2joWFx25h47n6sTpU2NjeNt6UHGY8RmRlDJtQDTc+m9z3Xh9dpR0rJ1FyYVS0B4vEEg5Nz+FxH3zTnow8s0JjOTE/S2aPoNHsP7Wd4sL8kztfd2ElkcmS+/XpaVPvVs1+m/paJoa8Y1LZ1MZtCJdrQsZpEPMbE4BHcVQGsttxUooVi9Jn7sbqUk43NTeFrUf4mn34Kue1SlPPNSBtpoDK2nNRpuJz2U9Pp2/zVAdqu2rHomtMqCMf1p1HyoWrcvG6F4bSN6zMzYy3FppXpTGoBv4cdV6SzTdktpOkHcP75+tSWpUQm/Vtry8f9mw9FX80afZs7a5UzEjanrk03r9FnQGupLd9ovhicfo5+XTfmoDHNB3q2tFc1pNkvU3tMhdMmSsYE13XaFt3rVQ2F02MaRd26dJu46lfk1U9TkdEuhU5O58NeZnTBzWrXn9TO55OLGSzrvVkW3Cx5yOa0WYrWI/lx2SwDRliU0u47gRfcLPYF9jftfLEC9Fm+BTdHCRndoPgFNyP2Re1bT45MA6Wyhc1h3BalXnCz2POrB2FzDi61QT52KVpgwI5iCFoHBFDMX18zVLhi3hoD3gXcmE1o1GTqGCqy5eFsabOUtxFFgnENWpRZpvsBLzCHijj7Xa6ygP3A64FnDaT9M2qDeBBw5aMHcDEqukto9m7Q7NJSqk4AbAB6AZdWhgvoA07L1+YFlP1NVLjoPmBtjjp6D4ro6C9oTHFGZAM+ppWzHXhhIW2pjPpXocLDf51sG3qyAWdpNvoMRYaEA63ACIqY50eVtgVwNjAEdKbKgmJFfBCDEZ9FynAuigsmoPW1J4HnldI2pdjn+zJgv5TyGalIdH4EvFUI4ZDppDpLkSTIeQRFPANAhvs6gRCKRGNdcq+igTJScYZW1g7te7b7NwBPaeVlTSuECKBi5n8DrBBC+HPIdQbwACou/RSjemjRRZ8BrpEK41LKYVRY8UfztEU2fBpFnRnSygihon8+Y1TWIrAR5RR3kruOkgREDxhIu7SMnaiOPD8fVWa9ckII0QT8A9UuXqfZHUiXTUr5EHAe8FrgWxqhUqFI9ott5GfHkkMI4UeF439ASnkwVRapCGzeCHxcCJHfoYb54wrgeq39SxS50xWp8hSLUjjfy1nMOrUX5bQuMXBvkmlqF7BKCJFtuXkjikFoGjUqW5clbbY8dmqfjTmYjJJp9wHVQohsR19sBB6TilHpSZTj1oUQogX1tnCY/OkNL0IRgfxqyfWvAu8QQmRetTQIIcQ6FEvW/y756X+A52shzGWBFlp9OvlRbz5iMG2m+44Khi4hxCqU8/sDiq8gZzi5lLIfRY14CnCTEKLQla9kW38CWFtEPqXAt4G7pZS36P0oVdj9R1D6GjwyIj8IIXzAq4GfpFz+OfDPQgjjq/w5UJTzFUL0oCp/qaGuA95rgKYtSfcYJmUUmC2t9v0RCus0yTx6Ua8S2WbvX44iX0+gXvOzde5XAM9q33M5gqTO0kDaeWgjm6tR0yWLOqZUnBG/Ijufq1F8GkU2PrOkjBlUx/h0CcrIhLOAWal4OrLSaWoPww0oNrZ87NiCIhF6Op/7ygkhxBnAPcB/Symv1tqGIUjFc/wyVHu+TQhRXYAIyTYZRDGenVxAHkVDCPFGFAnSB3Mk/Rmq3r9WJlE+DGyTUs5v+pVSDqHegovh/12MIudF7gSCOtdbUJPSp2a51wHEgQu1/58Cfp8l/RTwae37L1GEFvnI2qjJ1K79PwhcmyW9BD6pfb8PuDdL2kHgz9r376N4fzOlvQ+NhQ1FFB7BwJwd6nVLkjIPuOT387XfG4qozyTbVUuG31u1388vpt1kKf+/USRJAOtRrFXVGdKeo8liRzmeBHCegTLerN0nAI/2vWIMZ8D7UfObryoyHyvq9JPH8qkfFDtaPGk71Dznrytgh0tRrGJnGExfrfmEn5VBlijwU53rP0i2z1J8ig2yeKvWeBdBStkvhDgTNZ2QCTHUKQqPaf//AtWBMmEbiq0e1ChvJktaPYRQvJ3Jp9mvcsjnkmpEDnAzkG1/TzuqwgB+h5r/zYQdwB7t+zbgPqnVbA78EjW1kSkUahvKQY8YyCsTHgAuk+p1Ng1Syj4hxGWoudJy4OMsnHKyH9U+wnoJpZQPkBLRIoT4B+qIm6yQUt4ghPiVlFIKIYLAVtTC6rJDWyv4Duqop98Wk5eUMq4Rqz8A3AYY3RcYQx0v9IT2/y2ovrLciKEcqaHwVCnlpBDi80BNGWSpRzn2pXg3arG2JDBZzUyYqCCEEBappraO6jxNlB6m8zVhwoSJSiDbnITLYS/Lke1auoofN53Phu7kx+Zw5Qx6MBLgIGVpN9cbsbvTZhnIJ+ggGWjgcjryD/JwOrLaINtR8TZHCYJtsgTMZNa38ECRtL7jNBbY4HI6y9IPjLbtUgcqZPo4DQYKOQ32neTHaNBNPoEmToe9JH0yVz/IOvIVQsg/f+NjWCyCREJitVjwe11MTM/R0VzP4Ngk1V43NX4Pzx0awOdx8bx//SJ/evcGpIRwLEFTlYNgJM47bniK3sl0Zi5hcyJji6f1MoUJ66Vd9LvdOZiIhJoBLA7XgIyGm5amWZr3v3zzzyCgqr6NycHDCKsFp7cKm93JTR96KRNj+mxb9957L01NTczNKQ6If3rpyxkZTJ8qzaXff9+oprGFEDhcLmLRGH0H9tC0ohMAt8dLcG4Wi9WKlJLa+iZCoTmaV3RyeO+zRKNRZCLBx970Er78yvWsa/bR4HcQjCRw2i0MTauyO2s9nPWf9wAw+J3X8+N797C+tZoGv4tgJIbTbmUyGCUcjdNU5aanyU/TB36BlFIIIeRfb/w+VqsFm9VKOBJFSonVaqGpvpa5YJjOFS08t+8gwVAYl9PB8y57JzIL45QQQn76p3eClEQjYWoamomEgnz3/72KkeEhPvZ/f1bpENhdLuKxGIOH9lDfquzidHv5xgdfz8yoPgsVwJ+/+C8gBG11fg4PT2KxWKjyOHndF2+gb3w2432gQkJD0URz1kRZIISQ3/ripzhl3Woa62sJBkN0rmjluX0HsVotxGJxztl4Ks6ujVntVEz57/3en3H5qnD7qrFYrUwO93PDJ9/A2MhwevocfQsW969C5Lnhtq1IKYmEQzQ0txAKBnE4nUxPThKJhKlvbOLSc0/Nyx5CCLn+7V/G374OR3UD8XAQd0M7s/17ERYLVV2n8Ze3qk1N53z218m7sDrcJOJR5gb2425Q4fRWl5d4aJYHvvQa7vjx15P543I6iMXi7Dl4hM42pb7X42Z2LojVYkEiF/pBWxPP7T9CKBzG63Fz/uvem1GfnAtu55++sK3zhtu30d3aQLXPw8DoBBaLYFbrbKnpNq7wc8vOQToDLoKROKFYgt7JCL1Xp8drt121gy3X9S66tuOKNsNpl9w372xlNNyklzY177ardszzRiSZ0xxuH9HgLNHQHBNjoxnl2Lt3L1JKqqqqCIVCjAz268q244q2jPq1XbWD0zal03L2HdiDsFjw+PxEQiEcLhdISXvPOrz+hW2G605fTPThdliQQDCSIBSNI4RakTqltQq/a3FVu+2K4CcYiRGMqjpyWC101nmp96dvt77gHLUj62e/uZXu9jaq/T6CoTDjk9MEQ2G6aOXsDfntUFp5ylls++MNNLR1EwkFiYSCjAwPAbD2zPPT0g8e2oMQFtw+P5FQkJnRgYztYccVbWxerw6Vvumux+hqDOBzOZgNRegbn9Wt11S0XbUj7cGdL9791tfxs1/9QbUTn5dn9uzHYllwvOXGytPP5aE/30htaxcurx+ZSDA2MlxQ34LF/asQnHrG2fz+Fz9jRWc3oWCQUDBIJBwmEg6xev0pVAcKI2yyOtwgJfFwkEQ0RGjkCMJiweGvXUQ0Vbv+3LR75wb2g7DMs5fZvTUAXHD2hrS0mzeezM9/dwfd7S3YrFacDjtCWAiFw6zqXOBDOfs0YyEIhnc77Hh8Nz63CylhajbI6vYmYvEEA6OTdDQvjj944OCkYu8CpsNxeurd2vUphmej1HkUI1FPverkU7sfIDo5jN1fl5KHsbSu5h5kIkZ0Kn2RXy9tat6pyMSclkmOBWaxSdauXZu1vEz6ZUJL50rGRxZkWbFyNfFYjMN7n2HthrMzMpd11noYnomQfJvp8LkJeOw8OzjDhhWL94Z3NfgYngohUfvpexqriCcSDE4GOTg6y5ld+jElKzvalrDDdRAKR3j0qWe54JyNebGq7d65A5fHB1ISnJ6iqWt11vSNK1YyNbZgF8jcHlLR3RRQLG0s3KdXr7GEpHcywobWdCrKQrDtwZ34vB7VTqZn5pn0RsfGSSQSWCzlPUhm/2M7cLgVO1doZoqGTmXfTG169KFb0+wYHj6Eb+UZWErEItbetZLR4aH59tPds4ZYPEbvoQN4fIURN3maOglPDuPQ6tfd0KFY7iaHcVZnp59M3ptsU+7Gjoxptz/8BD6PW/nAmVlWd60gFo8zODJekNyGne+W0/Q7RmtDIO3aOZ3VumnjUrKh1Uf/VBiPw0osoRR2BloBgdXlwearzSttePggwmrDXpP+UJaJOL6uDYTH+7G6PPOdsrXamcYfrMeclprW47BS67GxZyQIwGte85q0tHqyZdKvtTpzENEpZ6U/oQHqm7OzWW3qTq8LgJbq9JHspp4G/bQ1mflHAc4763Td651t+dMbrt6YffRpJL1eHUdGF4/gkiPgVOi1r/G5GO01Th7tzXcXoz4yMem1NZefjxage4O+fTP1LT07Wp1epvc+RPXa/OoqE87YpM/U1lQEU1tgrT7Lnas2d5vMdK8ezj1T/22lrUm/L+WCYee79dFn6Wiup294DK/bRV21j0MDI7hdThpq/Iuc8I79k7QHnPRPRvA4LNR67TT7HVx2/VNp+Qqbk0c+sdgATqswnHbR73bnYOr3p75yme6c76Zr07cSHnxsGzVNHUyN9OJw+3BX1VJTW6+bFuDgwYMcOXIEn89HfX099U0turJl0i9Tvo/ffy9NKzoZ6e/F5fVSHahjfHiQqtp6xocHCDQ009Sm/3Q+PB6kfzKE12Gj1mtnfC5KndfBwbE5zulaqJ/tu4dor/PSPz6H12mj1udk//AMTruVaredyWCU1pr0yM177n+EzhUt9A4M4fN4qAtU0zc4zJqVnTy79wBNDXV5OeFnH95KfUsHY0N9uDxefDV11NXXMzqS/hajl9Zf38pTX7ksaxnbnjxIR2M1vaPT+FwOav1umms8uu0rFaWgRzx4pE+zlZu62gCDwyOs7u7k6d37lK1WlJcece/OrdQ2dzAx3IfT7cVbU0egtq6gvgWL+1cheGj7PbS2dzLY34vH66Omto7DB/ax9uTTeHbXY7R3Z+bCzobgyGFCY/1YnV4c/lpCo71Y7E5iwWndqYYkxp7ejru+Xd3rUvfODe7PmP7eBx+js62Z3oFhvB43dYEqDhzpx+tx01Bbk78Tzrpia+520F0dNnc7FLfKK6W522HBTuZuh0X1dgLtdsjbiMDtqFDAXeQIBQSuBT6Bis5683JUcjEf1PrUMNCDinpy5Eh/D/BCFPnOuhLKUY2K1mrQ/j8PFfZpJAy5BUUxeRbwuAF9x4GVmr52A/m7UFF0Xdr/pwBHAGsR+n4URfH4DeDjOdJejKKQfDeKdcpoGW9A0TR+FMVdsZzt6ibgX4B7SaGwXMbyv6Xp/WvgDctd/pL2thV4U8q1eq29rigy77ej2NA+C3wlz3s9WvtfCxwykH4fcBIwC1QVKnNeM/4aUU6Sxs8IuU1q2ooTmBjACtQTax8qvPWkTAlTGLgepfT6vQH4m1R0kaAoFkGRjuRCkjxoF7A6B/NTF4qbYx+KZc3IMu0/A49KKQ8ASCl3obh+X2zg3lwyG7FjoW0qtYzlZjJLyryTyvSDVDa/SrK4PQ/F4T1PxCWlHAGuRzGVFYNi6ncDimjpOaAqGzugEKIGxaH9DKqPbShEWMif1UytHKmRTtaGlOKcCqH8qxSStJWS3DL3AGNSylEDafPF5SheZAA0eX6kXc+FpA4hVGPKxRSXnHw2qsMVpFCIapjnOi0Q+TinVPrDNXnQHybvexTYoLXPskOjJ1yB6tzLPgjR9NzA0TEI+gyKlS+25PrXgLcJIYpZiVxEL2qAUTHtXq2fPUpuVsLHpArfLqrf59sALwSeSHFO2UZiJwMz2pPtCPAC7alxNONCFFUd2t/n5UibJCPZiWK+LxpCiPcAZ7JAIpTEDcDbhRDZnCkodrNHte9PoDiAM+FLQHJzZS59EUK8CsX1+7slP90MvFIIka2sTHmuR424D6NGEx2ZuJM1R3I2Cw+XA0DO5WqNoPufgF6p6CongNPylbVAnIc63SSmlfum5XL8Gl4L+DW9dwJnJg8iWE4IIT6OqrufLf1NStmHms68vcC861GMfIelIoWKA2vyyOJq1AkioPrBhVnSpvb7R7VyC0K+jeBjLLyKT6GeMJlea9/LAl/usygWsem8JVxe/BvQrX2vR80jZcLHWeA9DQHnFXmaQBL7ge/LdDLtPtSTPdf55i9lYRfLOrLzj/4Y+C/teyO5R68W4O9S8b7OQypO2W0oesd8sQf4kpRyTCoyejeK9lEPPahRZDLscDXGOIznUO3vSe3/FcAHCpC1EHyEhemcO4Gb5PKS3uxEEeGDcv4BFB3ncqMH2CrVaRR6+B0LDjBfTKDWlfZp/zeg/I9R/Ai15gCwCsXnmwkfYcGxe1HHgRWEvIh1tBFJQmrHaAghVknFLK+X1gk0SikPFyrcckMI0YV6esa115aVUp3MoZe2CTVfOqX9n9EWywntRIS9UkophPCgzpvKHrrE/Hx+Rn2XC0KIbtSih+5JDql2FkI0o96u8tqYK4RYAYwufYiUAxq5uVMqMu6K42hpp+WEEKIDGJQLlLD53GsHWqV2hJHO751Av5QyUmyfMVnNTJgwYaICWM65pxMeQghLrvk2IYRjueRZLpyoepswkRXZ9qE5bSJtY7KwpW+Ad1rF4o3blgI2xVcg6ELobLxeqku263q2SEtjdw5YrLaJfO0BSKfdlv33DLLq1pHNYjxtjnKTH5fDPmCx2Ud1ZXM4DOuZyY756Jf6sVutugEnue4T9uIDHnTblIFN+y6nvaiyM9VDNjsubh+iaN2LCeywWcRkVvtoAT9SSixWW1paw30xQ7BFOfp9zraSbdpBCCGvfVUPnQEXPqeVUDTBpT/cxZbrehnadguuhk6sbh+Pf+HF80xJtzw6xJW/3Uvff74wY756aP3U35FloNbLBiGE7Ln82nk9EpEQu665lN6rt3DLo0NpehuxRSISQsaiVK1VXBE7rlAx65/6uz41ZTb85wvrmLjt6xl/r3nZhzPKqldHA19/RVoezR/+o27ayb9/P6d81S9UaxpfuGss7bcvXFRL8NmthvR0rz1f147Z6mJpvS21+cgN6Wsm9W/+es77im2DQgipZ8+ZB3+d9T7f2a8pqmwhhHzXH9OpIgH+7xUNunaMxiWbu9QaV9tVO0qi+5e3judM98nzA2llCSHk8HXvynhPwxX/N3+PEEL+8JHFxFTvPKPKcF98yc/TqV/veEtLyft9Lnvm3HLSFXAxPBsl1UdP7X4Aq1OxJcXn1AaGJFNSR036YvwtD/fTWevC57JplZ5ASlhZ76GpqpKnVIOrsYtoCqsRKF28DkW5OB2Kz7M+GbFFkg1q9sjTeFesz1n+43fcRKClC4fXTywcBCGIR8LUtacTGd341wfpaqnD73ESCkezyqpXRwC/ePAwnXUe/E5VF9nS3njHDrpa6vF73YTCESwWC1JK1nQ0U+VdvMnl0dtvItDahdPjJxrOvo7189/eRld7K1U+D8FQOKMds+m3tN5czT2Ex/uJzU4AcPM9T9LZWI3f7SQUic6zrWW6T48Vr1Do2fOGP/2DrrYmqrweguEIFotASklXWxMNgeqSlQ3w3N9vxt/cicPjJxZWx7Hp2TGWkDw5MMtJTdnJlPLFw7fdRG1rJ06tfGGxEI2EqF/RQ1V9Zjrgm7c9R2eDH7/bQSgSm6+ztlpfWtokFWmSXhSy9MXDT+JpW9wXe++5BU9jB1a3n0Q0s42gPP0eDDjfczrTd39UrU7fqaKXDuD+AxN4nRq9ZChGT72HWELSNxmmdyJUceebjy5GbQHgDOQmmDn8xH043F4kkvDsFHUrVpGIx5ibGsMTWEzSsWPXPrxuB1JKpmZDrF7RmFVWPbnu3zc637imQjFWNfoypt3xxB68bicSjUJ0haIQ3dc3hM+9uM4OPq7pISWh2SnqNTrOTOhub2VodHzRAy+THfPRDxbs3tVUw/Dk7HwRq1oDhu4rBfTK6F7RzNDYBMk3zdWdbcTjcQ71DVNfU+gOqwzlN3cRnFg8oMhkx5Yy9L+61i6mx4fndW3oWE0iHmO0dx/eGn2qUoCuxiqGJ4MLddZcTTwhGZlOf5jr0YsardvxZ+9XzG1IYsEpvC2qvS5Xv08i67SDwypGo4n5TfjqBoMnTxwT0w42xyjx6CL9Mp2iYbdAdMnuTKPs/zIabirHtMOp//IFDg/r8AJb7RCPpl3Wm3bY8KW7GRxLz2M5px26L3otA/3pr4KZ6iKTfqnQm3ZY/b4fMD6ZeVdaMSc1zOeh06aAik47/PIdpzAxkp2QrNiTO5IyVGra4aMvP5mJgey7WpN9UW/a4Z73nURwKl32Yvp9zraUz4Q6as9ozu9Om6UQNrSKs5wZ1S/ftIWwp4Hxha+lH5dDsXOlymq3iIwLMovutVkGXA77oLFy7AOZdMtnwc1QWRo7lJG6sFstOXXV2N10663Ubcput+aWp8gFN2uebcxidw6WWvdiFtxy1Vnqgls2RrzkR0uTVr/CmnlhMsU2GdtGvt+zto1yNDidBvg14BpUdM1aYAAVDVWWBn+sfYD/1OwzzxSXyTYodqybUBFBb86nslPy+Akqmm8UaM7WaIBPavW3A3h+jrT/DPxZy/99OfRYg4rm+yzw7UL0MKCnD8U8dQXw22yyL2NdbwXeiIoQtZRJ7++hOBTQ+txrgftQvCxl1x0VYTaBYucLaO31A0bKRoVjP4hiRLwqRxuq0+z4NuDXRusXFc05hmIADGh2eQB49XK2jbLv89X2b74FRf83LqV8FhVSerHUIuVMsBHl3HaiMTJlsU2SIOYBA2mzlbeNJSxXGfJJlvdQHmnvz0OPbUXokQsbUCHF95Bb9rIjheTmdlTnX1VqeYQQrShWvGtT8v4NyhG+YJl0fwvwRynlpFbej4DLDZadbBc7tO/Z7HM68Bgq7H6e88RAOVcCN0sp+zWfJIH/QBH/TBiQsSRYjiCLS4BnpJS7U65dhzGGruMeS2g6d2KcUtFIWr3yXKhOv6sM5RWS9lHgtBLxYixFsiPvBQKZCHuWEauBYc05FFR/BvAR4GcyJZxZqlDtL6PeMsoKrT0vZb77O1ArhDCibyr9pVGGu2eAdo1BLpd8AeBfga8s+emPgAPFjbIsKKvz1SrivaRTEP4SuEAIkf3ExBMDJ6EqvZcclH8pNJ07tbSn50mdB/ACFLtX2EB5VShypGdRI4zn5WDkSnaGx4GTNV6DrGk1RzSNAXayAnAx8LRURDaPomxXSbwCSA5CSk7vKIRoAd4B/LfOzzcCXUKIC0tZpg5eiCJ/ujt5QbP/9RgjM0pSQxp5YCapIKMY59b9IPAHqfFRL5HxGuCzy8Y6V+a5n/WoSew0lnrUXNzdyzW/crR+UHOq2pvPPJl7U4a0rwKiKf/HgEvyLO8nKDIaUBSSCRTxSybZprTvXZpsNRnSbtHysqIe6hJ4eYa0VVraU1L0+FoZbCuBj2nf7wfuqXBdPwI8pX2/Epgrcf5PoAhlMv3+OxQxVjl17EVRaC69/k9afWQ8LQXo1NLUaf+PA1/MkNaGoo58qfb/Y8AdOWTzavn/U4bfrdrvWU9TKdWn3LyezwAbpZRHdH7r0ZQ9oSGl/LIQ4mvav4Ooua5QhuRJ3tMkbkctXuaDt7NAHfkYyill2rf1HPBbTc4DQgiHVKMMPYwBd0qNjSxH2hBqUSXJruVGOeBSI1WGm1CnKFQSZ6M6N8DfKP0r7r+i2lAmvIXs/M6lwIXotEkp5V+FEBuztAlQ1J/bWJh3/RWQ6aTTOGoR8SHt/xtRxwFlhJRyVgjxepTt9X6PCyFeyAL1aFlhspqZMGHCRAVgspqZMGHCRCVQzJxFPsEUhRzlDaU9zrtSn0KOXofcx6/nLNfgMfGpG9jT8jBw5LdLO+7b6PHcdqcr5zH3S9LntIPLYc8tp6O4QIa8bO+wGbO9w3j7dhgILkj9OFLsZrRuLAaZ3Sz23LI4Hfa86rlU9WQk2CM10COfY+XztVO2T1HTDkIIedt7NhCKJhBAS7WDIxNhrELgd1lx2CwEownaa5ysv+Z+/n7Nv2iEGdBa6+fwyBRWi6DK48RhsxKMxOhoqGZ335gyotXCCz/9U+Qyhx2XGkIIef1/fJiWhlosFkEiIbFaLPh9HiamZnjrZ77J8HB6aGim8Npc4Y3J0EYhhLz9UxcjJYSjcZprPMxFYrz1O3+jd3zOcHnf+PZ3OfmUU2lsbGJubg4pJa+55CX0D6XLfO41f8fmqUJYrITGB3AFmnn48//EzMTi8Op//9lfsdpsRCNhkBKLxUp1fSPhYBCH00kkHGZueoKahmY+dPHGnG1ACCG3X3cV1T4PVouFvpFxGgPVvOh9X2JgLPvpVaUIrdWTZ+t3rqTa68ZqsdA/OklDwM/zP/J9RsfGs9+bITRVCCG//PPbEcKClAksFisen5+ZqQma2joZGxnE66tidmYKmUjw0de/YN5uQgi56eo/g5QkoiGcgWbi4SAgSUTVyT7Omgbu+dA5hvqbEEJuuOLLVHWsx1ndQDwcRGp5CSEIrNrI717fzJ+/8bHFbd7rYmJ6jo7mel703i8xMJ5eN3rtO1Obz9RmL77yqzStPAlfbQPRUJCa5g5GDj2HxWrD6fXzrTefvcg2p3/q1/N2FRYLNpef6Nwk7vp2wpND2JxerC4v0ekxbJ4q7vv4uUX7paIX3E5rXdhad8vOIToDTjxOK7ORBBPBGFJCvErxZJ++cqE93XT3Lroaq/G6HMyEoghtzafK4+TMVaUjOTla8LqXLpxN+fM/3kn3iiaklDgddoaHh9lyXfpJPzuuaJun6kxF21U7dNOn3NeU/H5GdwM3b99DV4OfuUiMUDRG7/hcxnyXXm+7agfvevd7+flPf4KUEr+/inA4RP/QsG5af8dJixijQmN9zEyMLkrbdtUO1p2h/r/rdzfQ1N6Fy+tnemIMi7AwNz1BS9dqutadmlFHPTy2+xDdrQ34PW4SCcnQ+CQDY9O6ui6RuylrggJxSncrN/7tIbqaa/F7XAyOTTE6Np617mBx/S3Fqeeo8xr/9puf09zejZQSu8PJ+MgQsUgEr7+K9p61uvfW9Gycr5t4OEgiGsLqcCOsVhz+Wtz17XnpZ3W6kVISDweJR0JYnW4S0RC+lp75NOefviDLDbdvo7u1gWqfh4HRCQbG9etGr33vuKLNcB9pu2oH57zych69/SaQEqfXz/DBZxFCkIjHqGnuSMsnsE7l0b/1FtwNnYDEYnMQGjmCo7oeV0MnFpsdV/2KvGyUDSXd7dBV62J4JkLyOdRT7yaWkDwzmD7K6m6qYWhydj7tqpZaYokEzxweYe2KOvLfvnpsYPvOp/B5XEgJUzNzrO5UHKNTux8gOjmM3a+2NaZSKg7PRqnzqLMpUykjl6aXiRjRycVHhd23exCv04aUkulghJ7m6qz5Lr0OsH3bVnw+H1JKpqYmWb1mbca0mRij9NI+8/B2XB7FhjY3M0lr12oS8ThT46PU1OfvD1e2NjI0PkXyZW51e1NGXWMJydhcjPWNpaVTTMWOJ/crJjpgai7E6jbFVJep7mQ0jKuxy1DeLR0rmRgdAq0HtXWvJh6L03dwH1WBemx2/bNMPU2dhCeHcWj3uRs6kPEYc4P7cdXl51i8TV2EUug5PY0dOPwB5oYP4/CncQul1Q8Yb9961zL1EUhh2mOBaS8RjzHedxCLNbPbczd2EpkcWdCppQcZjzF94HESsci8ky4FSup886Gt27xOv6Jba/2lFOmow7kbT9K9LhNxfF0bCI/3K+eVUDuvWqudCAEeh5Vaj40DY2oXmjPQCgisLg82Xy3h4YNgseBYQmm3ebW+E1ua7+GJsO51gHPPO183j7iUbGj10T8VxuNQuwYDa/VjJVLTJrHuzHN109Y2tepez4Utp+nH7CzVqX8qQq3HzlwkjsVSvof8lpO7da/r1XVktBebv5bweDrjlh5OPkvfdvXN2W2XqX5ctfm/bdat08/LnSEvvfpZ2oZiCeX0lrZvMN5HADpP26wrQ1VDdvvUrNHXyVmAfXKhZM53x/5J2gNO+icjeJxaI5+MsKbRzdMDi0e+2546REdDNX1j03hdDmr9bg4NTdLVVMPBoQk2rS3d0P5ow70P76KztZHewVG8Hhf1NVXU19fz1FfST6B2WgWbrn0k7bqwOXnkE5kDwoTdOb/Xc/uzA7TX++gbn8XrtFPnc9Jc7dLNN1N5hw4epLf3CF6vj/r6evbu3UNbcyOXXZ++BXPs6e24G9oJjfVjdXpx+Gvx1dTppn3qwXtpaOtkdKAXl8dHVaCOod6DVNc14HR58nbChwZG6Rsew+t2UVftY1/vEG11Vbo6LdLbJrLzLRaIQ0Pj9I1M4HU5qavyMjQ+TWN9nW5dpyK1/vTwxAP30tTWychALy6Pl6pAPcHZaZwuN6HgHC63h8a29FdrvboJDh3E6vQQj4YIrMnvRPmRp7bjaWgnONqPzeXFUVVLcKQXu7ea8OTi9YCtjz5LR3P9ovppDvh024Ve+xY2Z1595MCj26hp7mBquBeH24enupaJgUO4q2oJTqVToAKMP7MDd307obE+bC4vdl8twZHD2H0BojPjuGpbSzrtUNRqnbnbweDKt7nbYdHH3O2QKpO526HU9XSs7HYoeaMD3oTibvgo8M0caTeiYrIvAf6yXB3jaPgA7wf+D8WmdPUylPcl4GoUw9S7C8xjByqC6SCwOkfaHwHvQUXhvSJH2o8B30QxcRUV2omiBxwFulERUxnDWZexrm8G3opiV3thCfN9HSoC8UPAdw3e82bgtpT/vwn8e5Fy7AZORnF05KJz/APwGlRk2pZlsP1DqND3PqDTYPt5DI0+FahBRdzVlVq2cgRZFMJK9AiwsQCSmGMZ+dip4uVprGOnohpmPnVb6rS50A5EpJT7gQMo4qJKo1x1XUi+V6AejEn8CHh7oaxyOuRLp+e4ZdnavRDCjqr/x/Mo70zAj0YMJKWcAG5FPbRKinI739MNsmD1o4hW2sogz9GKRQ+eZSyv0Ea/BkXaMpErD43DeS2K6CXvh3ABsunlhcGyywohhB9FmPRMGeRJ6vooBmg5hRA9KN7bPySvSSkfA4ZQbGSFYAPwhJQyRu520YBybPtzpS0R1gMHpZSzeZR3BfAjqVjOkrgOuKLUg8OSOl/tKfhCoE9KOQZMAqdlueVcFK2gRJGrfKaU8hytEEJ4WHgiHwRWCCEuKGN53SjSkUOo169zNPrBfHARSl5QHeiTWdJuAg5JKedQDvWcTI5BowzsQhGoHADWCiE25ClbKq5BnXCAJu9FReRVCvwbauoj6Zw2l4KyUOOufQnQL6WcBEbI7Vz+ANwvFZ1oKm5HTY0Ugv8Ckqt7j6GY8jLhQmCX1t9ngXeW+W33C6hpA1C2z9rHhBCrUFNlv1jy010oIrD0gwGLQKlZzWZRgieXMFeg+HzfvTShRup9BpA80fA/WRixHO+4FMV5OiellEKI61ngeS0HLgeqtbL2A18kO/uVHj6KYpICxRfblyXtv6EaK6j511YUgfuzOmlfD7iklFEhRAz4GcoJF4ofobhgAepRR8y8vYj8isXfUccZgbLFSqAJ9bZXDOZQfS35QOxErSO8I8s9e1DsbkvxK+BFBcrx7ynfnaijpDLhw6g3IoA/AT/RHHG5cAtwp/Y9ATxfCCGylDmNot3cm3pRSpkQQvwOSD9GuQiUldVMCNEGjOg8aZO/d8klpMYnArSnfYeU8uAylWdHndWW/XjX7Hk0ArPaK1yutB7AJ7XTFLLVszYKbC+HLTQ7dx5NbUwI0a3NR5c631ZgTEqZiY607NDs3ZVJP+0UCWTljnE6qvyNSSlpwoQJExWASSl5HEMIYRFCZJ1a0hbHypqHiWMXx1P9H3W6FLpHzW4Ro+htrLYK/Q3XKddtDmfeG68xuNn+aPyIlE3cTpslb70dNstIXnVjtSQKsW/yI2xOactQj5nSG20HemntVmMBOEs337vs+oEMemUs+r0EG+R17W6z5tUnFqWxCV2Z7DbrRL62z6U/IG12R9YACGGxGa5/I3VtsxhvT/P1nSX4Z+knU6CExV6YrwGkxWrcBvN6Ooz7qIKnHYQQsv8rL0m73vLxO+i9egu3PDpEZ8CFz2klFE1w6Q93zV+/8rd7+eEjU3mX+c4zqpDHIL2kEEJuua6XoW23sPdHVzL0g2xrIulo/Nfr89JbCCEn/vRfecuZRM0lnwBg/Lf/niOlQuBVnyepn6uhE6vbx+NfeHHGdqCXduquH+Ysp+qidy6ygxBCjv3qc2npai/7YloZiUgIGYtStXYzO65oK0s7EkLImfuWLpSDb/PrdW0RjUs2dyk+lLardujKJISQwWe3ZizTvfZ8ei6/dpGeu665lOf9ONt6KNzz9lb+vi+d8CqJF6708E8/M7Ym+Ne3tmSs66RsT/7Xqxn83psM5ZdE0/tuNFxPQgh58Y3p8t76phbO+1F2FrlM2HZ5G1/fMZHXPR/eUmNY5qJ3O9zyUC8ddR78msFBsQx5HVakhOlQfBFjlteRvuNo2x9voKGtG7fPTyQURFgsWCxW/DV11LWmx6gfi5ja/QBWpzft+s3bd9PV4MfnchCKxhAIqj0O/C47TTWlZ9y68e8P09VUi9/jJBSJYhEWPC47q9oasNty77O/6c6ddDYH8LtdhCJRkhuFRh+6FVd9B0iJvaoRyNwO5m0hJfG5BT7XJOWg3+MmGI5gsQisFgt11X46mjMfYnvTXY/R1RjA73EQjMR0y0gyh80ceDxjPqXCDbfeTVdbI1VepQfo2yKWkDw5MMtJTcbq+ee/vY2u9laqfB6CoTAWi5o1dDV2EU1hFwMY0KgRkw45EY+ClHhaVuGobkjL+45f/5yW9m68fj/hUPY1u757b8Hd2IHN5SceDWXUb5FsKfjFffvorPfhd9kJRuMIQAhY2VhFjae4t/4jGmWmze0nHsmux9C2W3A2dGJz+UhEQyRiUawuH77OU9LSPnjrjdS1deH0+omGQwhhwWqzsWLthoJlLdr5dtZ5GJ4JI+WC0TKxm2W63rhiJVNjQ/ONp6lrNYl4jMmRgePG+VatTictUXSPdtVgNbrHeDzB6EyYlY36tioGO57cj9flQCLnKQ5j8QT7+kdZ12Fs+r+ruZbhyZn5fr66rR6AurMuTkubqb71bAH6lJCxeIKB0cmMzve+pw+l6BRmVWtd1jKcgdKzU6Vi+6PP4HW7kFIyOTPH6g5FDpQP418mdLe3MjQ6Pt9PVnervqGna5Ia0Y5K69EePnMDe7F5FsvyxIPbcXt8gGR2eooV3frscLBAGYpUlKEejTI0n7ruqvcxPB2ar+eeJj/xhGRiNlyU8x17RqMzlZLo3BS+1lUZ00499wAW7eEcC07j1uwTHjlCIhbFYltMyVm3opvpsSGSMwWNnauJx2Ic2PUgK9achs1hvB6TKNr5buoOLPp/RY2Ltqt2pKWzW9C9DrB6oz5HZqCxMGrBow3C7hzUI8jORPfYEkgfIZcCmSgOW+urF/3f3FDHwPCobtotJ3WmXautrmLHFYuDE51WoV/fVnta2vm8M1FCNgR0rwNsXp/+cG6qr81YBgA2R/oRHCXCuaevS7vW3hjI2PaTMMKsdt5Z6aOs2lp9XaszUSPqPHxOPVufnlIPepSU/rqmvOp606pGw+Xlg9oMFJd6qMrA4Jbp4bxyg76PqinGRxW6uJAPo5nDKgaT9wEBe57sTMnPsbrgtniRyBjTWOonn4UHKY0zamX7FMpCpyu/xtxFCulK8jsQMMJIpvJZvOBmt1p0F7jS7Wcb0Cu75HWbhx5G5SmEEU9Yc7OJOXIwy1kMLNrl2Z7yZjgrxYKbkcXHTJ9CNgbks+BWkkYHVKGFCwK/KaSBo6K+bgd+DHygnJ3kaPsAXwY+j4oMPKOcuqMikr4JBFARiGOo0ON86+sIilXrqVLKC3wLFU13AFhnJG9UGOm3NZ3aNJ28lWg/KA6MEaApKTsq0m4IxfxVlEyaXnOoqMU/5LIPikfh9cBuA2n/DFym5e/Olh74GvApVGTmqYW0AVRE68WavUQheWTI93Nan3oIOD+HHpcBvwduBN6VI+3JwHNae7u2WHlLtc93A4oa8h5UyDAy/yiWjSgegPu074XkcawiSZDyMIXbLyc0foW3A9dJKcellEeA+4FX51OeFu3mQ9EZdgkhvCWU9wzysIUWIfd2FBnKuJSyF0V9eVmF2s/XgK9IKQdByS6lHEFRel6LoicsBqcBT6NYt7LaR4soqwd+A7QKIapz2GQj8CDKwZyaLW8W+mtBbVYI4USFGt9JCqlWieos2YYeNCBbMu39eaTdTgl8VKmcb7Ii9gC1Qoj0A5xyI6nYTirMRLWc0EIyk/YrN8PZi1DMZKlL/tehmJzywUYUIVIU5QjyO+kyAzRHuoH8GM5egAqr3Zly7TrUyHBZIYR4KbAO9WaxFN9HvWlcUmQxybayD/BpTGGZcDrwmFZPT6BsqwshRDPgQJEvZe2DWps9neKY6E4G9kopg7nKKwBJGxnJN5++l5rv6cWSApXK+V4MPCMVDZsRTk89JEd/TwDrjpWomRIgOWPfR/kfPJ9gMZcrwB+BU4QQ+ZSbSts4gCKvKQVWAaNSMeIZtcUngeuXXPsTqg2dWSK5ckLjz7gW+LDU4TLRHOCVwNe1UV+huATV1ySKSjKbjVLraQ/wylxptXxz2X4jEJeKu6PQNpsq23NkJ+QxDG3gV4six8n1EHGjmM52ofzWqTki4JI2GkYRgumvYBtEqZzvi4HkJlEXak7EMIQQm1Gjgv1S0RBayM7OdDzhYwBao98LbNFGISWFRkH4fNQr0zw0R2Eh3Slnw8dZYDiLUNjDVg+fZGEHzn7ghUKI6kyJNQKfF5KuUwR1IsFSp1xO/BVoRjl+XUgp7wCqgXuLKOelQHIflJPsfe1TqIUggAbgtVnSfgHVd0HNwWbjr72UBdrOvcDzhBD1WaVOx+dY0KMGdbpFKfBBIKENBHcDG4QQKzOkDaDm0EeklFOaPG/US6hN4VyEeuMA1Wey0armRKkoJZN8pQA/R1V0PhgF/ialTHbo37KE1u04xqMsPAQHgG2UmLoOQEo5o83N6oU1rUa9wmaj20vFP1CLFEgpX1VCMR8CktvA9qPmbnUZ8bSy57LotBbFO7xcuBY1/ZHLfpeiBhqFwrGkr2XbCP8P1HwvKKedLYrmHhb63FZgayZdpJRfEEJ8Sfv3COrhl2+b/QeKvhHgX3LIlg92oY4xA5hCPeh0mfiklH2oh3QSfyAznWkI1R6TzIA3oN4mCobJambChAkTFYDJambChAkTFUDeztftsA8IIWS2j1ttIjdRZrjd7px1kevjsltzpnG7nPFiy1nIy5W1bbgdtqJ0crpcxvR2uw23Ubczd5tP09OZ3gdsTmP1ZXO6B6yO/OrW6lisj91gWcmP3alvj3xkNmrPebvmaL/uPOooFVaHq+h+sdi22dtsoch72kEIIb/6zpdyUkcjDTVeguEoUkrecM3N9E9kP+TAaRODoWii2eJwDchoOC221mkVhOOZ5Unen5fARxlcdstAOCYX6S5sTmQs49SmSmN3DiYioUW6CyHkd35wPSs6OpL/43a7iUaj7Nuzh/bOTgB8Ph8zMzNYrVaklDQ2NROcm6Ojs4ue1jq+/NrTWd9STYPfSTAaR0pFdBKOJrjiRzvonwzx11t+tFCGy0U0FmPP/oN0rlCbNXxeDzOzc/NlNDXWEwyGcDodTE5NEwqFaW5q4NQLX4HUWJ/0bAHw7beew4par1YeuOxWYnHJvqFp2uvUda/Txmw4htUikBIaq1wEIzFe8OW/8Ms/34nT5QQpVbktLQTn5pBSIoRgcnKS1138wnk5ckEIIX/4sTfRXFeFRQgSUmK1WPB7nEzMBOloqmVobJoqrwuX087Q2DQv+si30/IXQsiXXfN7rHYlWzwaxl3bTDysZEtEI8RjUW779KUAPP+Lf0RYrSSiEZASYbHirGlg2+cvYXpicfi3Xht667V/QlgtWKw24pEIEonFYsUbaOCmD72UibHceQC85tq/gJTEoiG8tc3EwkH+eNUbCY5mZz1LbbOZ6vp73/sep556Kk1NTcxpdTQ5OQnARRddlLOOMvmSk/71m7jqk1PrAqvDRSIeJTiwH1dDOwBWp5fHrn0bkYn0yO5MvihXX9Xrp5lQ0IKb22lHIgmGowQjMYSA/olZeq/Wj39Oou2qHU0AMhpu2nJdOs3bjivasuaRvP9YRjgmm5bq2HbVDvTskQo9bgiA17/5rbrp9+3Zg8Viwe+vIhQK4na7CQaDrF6zjsamxVm5HTYkEIzGCUXjCASxRIKWGjf9k4oZ6nlbzk4rY8/+g1gsFqr8PoKhEG6Xi2AoxCnr1lAbyLhJYR6ZbPG6Tfo7ePYNTWMRAr/LRjAax2lXazSntQewWxde4jafdwG/vPGndHStpLq6mvGxUYTFAlKyas16TqrKn7TososWdizd+LeH6GquRUpw2m0Mj08TS8RxOe10NAboaMzMRdF88hZ233kz/qYuHN4qwtNjCAQObzX2mkY8tQt1U7/uHA7c9Qu8TZ3YPVXEI0EiM+NMT4ym9ZOlbWjHFW10bFCcDY/fcRM1LV24vFXEwkGC0+NMjOXOI5lP09ozeOZvN1PV3EksHCQWCREc7c+rzWaq6/e+97385Cc/QUpJVVUVoVAIl8vFpk3GeBr0fMmOK9poOV9/Y0dwYD8ICzaN7S0yMairRyZflKuvZuqneijI+XY3BRianCU5aF7VqmIqHjg4xfBslDqP2kGSpM0bm4ul0eZN7X6A6OQwdr/aseJq7smax0QwxvGCW58aXaQf6NtDJmLEZifwrlifdxldK1cyPLTAwrRq9Vri8RgHD+wjUFuL3b7A2tRV52V4OryQttFPLCE5OJr9TWZlZztDI6Pz963p6SIWi/Pcvv2cedrJi8rIhKX1nVWnBh/DUyEkaptsT2MV8USCp/smWNtcPe+MATq7VzKSon/P6jXEYjGee+ZJNpyR/iAxih1P7sfrdiBhETPc6NQs7Q01hvKoau4iODFMchdYdVsPiXicudH+Rc4XwNfURSiFLtLfqt9PIL0NJRFo7WZ2fIE1sLZ9Vd55VLd0MTe+mLYyU5uNjPbi6z49TW+98rZu3YrP55sf8a5du5ZYLMYTTzyR25A5ZNaDu7GTyNRITj305M3VV2U0+9vrUhTkfDevb9e93lrtRAjwOKzUemyMzcVoq3ZyZCKMWLJlUCbi+Lo2EB7vVzRwiZhuHgfHwwigtfr4ibnY0OqjfyqMx2ElllCNQM8ekdFeLHYX4fH8D7rdfO75utdbWnVYpnr0t2i21LizlnHeOWfoXm9rMf6CsrS+s2FTj/4OxhYd3uNzthjXPx8YZYbLhqaTNute99alM2rVr9cfAerZLbUNpaL9VP3ycuVhdS3YteXk9DwytVmbt4apPQ8aKu/88/Xrqa3NeD05A62AwOryYPNlD66t0WFly+SL4lLq9tWl5YWHD2Lz12JxZO8vS1GQ89325EE6GmvoHZ3C53JQ63fTXONh07WPZL0vSZsn7M7Bp75yme6cb7Y8jNDuHe1w2sTgpmsfSZvzfeorl2W9T9idhnXfdu/ddHR20dd7BK/XR119Pfv27qGxsYmxsVE2bTlvUfrDY7P0TwTxOm3Uep0cHJ2lu97L3uEZVgTcHBnX38J5z44H6Wxvo7d/EJ/XQ12ghr0HDtHS3IjH5crphPVskQnbdw/RXuelf3xOyelzMjIdptbnpHdslnOWOOYdW++hvaOT/j5lg0BdPQf27aW5pQWXuzCS+q1P7KWjqZa+kQm8Lid1VV729Y/Q0VTLocExVrbUG3LCA7u242tsZ3a0D7vLi7OqjujcNNG5aTz1iykKh5/cjqexneBoPzaXF6e/Fn+gLq2fZGtDBx/bRk1TB1MjvTjcPtxVtdTU1hvOo/eJbVQ1djAz0ofd7cVVVYe7riWvNpupru+++266uro4cuQIPp+P+vp6pqam0gZr2cp45BObDLWh8Wd24KpvJzzWh9Xlxe6rxRHQ18NpFVx2/VPp5dmcPPKJzFMi+fTTvJl4Mp2blfpx2W3HPPXjsfBxuQqj5kz9GDlTzuXMft5XPh+XM/v5aYVQbqZ+HE5jNIBOl3Hqv0IoOpM0mqkfbdU8571Wh2vAYs+vbi32xfrYDJaV/GSiQsxH5lK3X6fTOZhvnlJmppcs9GMp05l/hd+oIkPGUPHNc6got4o7JPOzqI4uBW4D3otiMsuWdjUquuciYHseZZyB4uO4BLhjGXS6BPgL8K/A9TnS9qCIYi4A7itB2RZUlNPbllzvQkVptueRVz0wiSK7eSZHWoGK/OtBRZI5C5D9VOAZ4CXAnQXq/yHge8BXgM+WsE47UNGdm4GHl6ENbUIR5Lwa+FO5y8v0KSbIogMISSn3aw38pCLyMlEeJMlLdmKMsWknKtz5NKHoJ/Mt4wxh9H2xcBSqUy7SFCN4EyoM9mepF6WUB4DvAvmcWrpRk+spoEMo7o1MaEONwvahQoDTDxkzVt683Qqsp0V1XcD9ufJ9HFgvyk+qVS498kIxzvcM1NMDyk+FaKIwJOvISKM+A3hESjkBDKJIwY2WsRPFyibReFnLiKROTwBrRXaGsDNQLFTTmnxrCy1Uc45fBj4oFWnLUvwXcIEQ4jyd3zLJ9ohUbGdPkoXuMSWtpPC+lrTFEOpNtavAPMpBfZrUbw7F6VHugVxSjwOAWwhRkS2sxTjf56M6AKjOfVHR0pgoGbSR69moDjeH4mp9V5ZbzkeNxECRkzzfYFHvA6KaY9hFGdvBEp1CKJ3ek+WWVJ2qyZNtbwn+AGyTUuoexialnEWxXP1CZGFiS8HzUDSGkNveS/vahYYkXozzWKBwzKd+ARBC1KCmpnah2MIahBClOmTxfIzboihoI/4tLNBnlrXNZkMxzvd9LDAqNVA6TlcTpcEqoAU1Lw/wdRRzVRqEIjE/jwUGsXXARwyW83/Arwq4rxCsRI2sk6FZXwPu0kuodbILgKh26d+BXxRR9vksmW7QwS9RtJL6e7sW4+Wohwcop3ZllrTvZ2GkWgu8xUD+8xCKa/gs1IgXYD3w4XzyAF6ForCMaCN/b75yZJBNoAjxk28T5W5DPtS0zZT2/1ryt0VJUDCrmRCiHTgipZSaAdullIdKKp2JoiCE6JRSHsw3rRDCizrDayTP8vyATZbx+J5CdTrasMTeDqBWSqnLISCEWAH0Synjhfa1JeX5UdSU+kdU699vAVYky02VKR85DMjmBvza9EhZsKS8apQfnChXeRnlKNT5mjBhwoSJwmFSSpowYcJEJWB0T5rQ2bjstIqsm5OdNmEGWyzTx2kT8/VjtWcPNMhUb8Kmf5/NUVh+xbaDVJ2SH7vNmlN2p10/TVYZDQZnOByOYT1Z7VbLaKnsrXc9Hxvr2S1befO/pwQTlCIPo3VainwzffT8VjnbbF6ySSkxAiGE7Ln8WlwNnVg1RqBd11xK79VbuOXRIToDLnxOK6FogmhcsrmrirardiAN0vaZKA5CCJmsiyt/u5eP/iXzdN5XX1ynW2+X/nAXW67rZWjbLWn1/PUdExnz+/CWmrK0g1Sdkvm++PuPM3P/LWlpfZteNy/73h9dydgvP5NXWbWv/Q9iU8M509mqGnR1EULIwe++QfeepvffnLe9i+lrenbLVp6MRalau5kdV7QZymOpbMn7gUV56KEUsuUDIYTMZONK+668Np1bnV6Qkvjc9CLmH6/DipQwHYrPs5A90TdTFoFNZEayLpZi118UpaDD4ycWCS5Km1pvoBib9Oo5FQ/eeiN1bV04vX6i4VDG/GIJyWO9xbWDpfkmccOtd9HV2kSV100wHFks+xLcdNfjdDXV4Hc75ylQqz0uGqo91PgWk6H89Iab6e7upMrvJxgMYbFYCIaCrFuzmqbGRkMy/+K+/XTWe/G77ASjcV09ctnb1dhFdHIxi1gmG+8ZTufeyKc8mYgxczCdRSxTHktlczX3EB7vJzYzbsg++coW7C/qqLSMNs7HnuVAXs637qyL066d06nPjdpSVczp2CYKgV5dHNl1Hw63Fykl4dmpeTrBTPVWtfqcrGXse2wHDo/KLzQzRWPn6qz5FdsO9PLd/ugzeN0uJJLJ2TlWd7RmlV2PAjUcjfNs7yib1i4+y3Llyi6GhoZJvhGuXb2KWCzOvv0HqQ1k5ulN4v49w3idNqSEqWCUnqaqjHpkk1nveqY89JBvec5AOqNaKfIohWzFIlO++dizHDA+7WBzjBKPLuJry3XyhMPKcDgmjQ0XTBSFpScFZJt2+J/XrmJmUmeUYrVDPJp+HbJOO1z9spVMToxl/L3QE0gcVjEaTZDGEag37bDq0g8wMLiwO+lomnY487O/12eGy2Rvnev59LVMp0Zkq19YfApDJtvnk4ceSiFbPtDzWwB2C0T14hQ1LMupOYVOFgOBfL6bn+X75Mtolfxo96XVXyH5JVmyStkGgIBLnQ+YfbGkjAturgxsaPmysTltlsGlds63T+XT1/TSFnt/vnmUS7Ziyypnedk+5j7fEwRCiA8Ap6Eipb4rpfy9ECIgCwyIEEIcQYUrf0NKuVa7VnB+BcrwXuBMoB34XynlbzLJIIR4PvAl4GFgUEr5H1nSNqMIbz4PbJJSvjVf3YQQb0JFhUngNinl9cttHxNHN8x9vicOkkxOD2rfKcLxNqDCS/8GtGsRcQXnVwSSpD4PkFunpP735ZF2m4G0mZDM4/4i8jBxHMN0vicONqKYnHZSPCPVRuBRqRi5nkaNqCuBQugl80n7JLBSCFHI0Rf5lGfiBITpfE8ACCEaUWQiT1AaDtNXoZitoEJ0okKIehQN4xMGZUg+fJ4DmnIwj21EURxGgMPAP+UpmwtF2L0Txap2usaNYMLEPMwGcWKgG1XXYRSHaZsQ4twi8ns1kDwq1gp8tijpCkMn6oSHIHAQaBFCPE8voRBiNXAysEcqIpgE8G8Z0jqA1wDJUyibgOyHlaVjFYo9a0ZKOQa4CsjDxHGOYpn9TRwDkFLeT0pdCyHuAPJiLFuCFtRCEiiaxmVvR1LKh1ms0+2oo3b0MAX8A5jV/r8ZxeOqhxhqrjd5UEAdC3SHRmXbJYSwyQXGr9+jHhAmTMzD3O1gwoQJExWAOe1gwoQJExWA6XyPcbjd7gEhhCzFx+12p5F5u13OnPm7XU5dEvCC9HHYSqaPEEK61bHvecPpym5Xp8s94Hba85bV7bSXzFYmjm2Y0w7HOIQQ8q677kp+x+12E41G2b17N11dXQD4fD5mZmZ4zevfyOhgf+a8bE4S0dCi0FkhhLz/Nz+gxu/DYrXQNzhKU32A8974QUZHMofjFhwOKoT87nteyop6v/ofgcthIxZPsG9gnPYGFY/vdTmYDUV4x3f+wtjE5KI8MoXiCpsTGQsbSgvwjV/8jUB9I+HQHFJKnC43M1MT1NQ18pYL1RmPt3/1/2GzWghHY0gpsVosNAb8XPKxb9M/np1UaFlCWE0ctTAX3I4DXHjhhWnXzj33XH7yk5+wcuVKbDYbTqeT0cF+tlzXmzGfHVfoHzx86toefv67O+hub8Hv9TIwPMroyHCuvAo+Efb1F+gfXrtvYByLEPjdTkKRKC67jbGJyTQ5dlzRRu/VW9Lub7tqR15p+w7tQ0qJ1+8nEg4Ti0aIhMO0tHfNp9t8cjcAN/71Qbpa6vB5nIxNzdI/PqOb75IyKnJqromjA6bzPU6xdetWfD4fUkomJydZu1admj760K3Y/WqXWJKyT0bDuBq7Mua1/eEn8HncSAlTM7Os7lJMYFO7HyA6OZyWX3QyN0FNIehqqmF4ETtZQFcnUHSBw7NR6jx2gEW0hakyZ0vb2rGS8ZEhkhs7VnSvJh6P8fgD29Jk626pY2himtQ3Sb18YwnJ2FyM9Y2FxG2YOJ5gOt/jFOeff77udV/XBsLj/VhdHmQiRmS0F5u/lvB45umIc888Vfe6TMR188NSnqWEzWv1R+ZLZQCIS8mGVh/9U2E8DiuxhHKKzkArILC6PNh8tVnTnnq2/lbohuZ0ObacsjLtml6+B8ZCdNW6ePjIdN76mzi+YDrf4xB33303XV1dHDlyBJ/PR319Pfv27aO+qYVHPrEp433Cps+9e++Dj9HZ1kzvwDBej5u6QBV1dfU89ZUscQM2R0lPn9329GE66qvpG5vG63JQ53cxPhOiLlCdppPTKrjs+qfS8hA2p+G0AIO9hxju78Xt9VIVqKPv4D4cTif1S5zv1sf30NFUS9/IJF63g7oqLy0BX8Z858u2iUEjups4PmEuuB3jcLvdA6FQqCRzhy6XazAYDC5aAHK7nAOhcCRr/i6nYzAYCpdk4cjtsA2EovGSzYW67NbBYCSWt2xOl3sgEs5sV4fTNWiRMUKRWF6yuhy2wWA4ai6ymTCd7/EMIcQ/A+8B/gCcJaW8osj8dgCfAH4GvEhKuTvHLSWHEOISVGjwr4BzpZRvL3N5/wqciwrLdkgpP50l7QXAV4GvAW+SUr6ynLKZOLZh7vM9vpFk1nqEIsl0hBBWFHvZY1SITEdDkkZyuWRILS+XDZNpTSYzEzlhOt/jG0kmryeAtRppTKFYC/RLKSeprHNJ6rQLWKMxiC1HeTuBjUKIbCfaJtPuBQJCiLosaU2c4DCd73EKbaR6NrBTSjmHokbcXESWL2CBjOZR4IKiBCwAmk7noHQKoaYCimFny1Veo1ZeP3AEsAPpxzmrtALYosmWAPzAx8slm4ljH6bzPX6xCsU+ljxJcyXw/iLyuxJYr30PAedVgKO2G2hlsU4fKGN5I6ijhPZKtTgSAC7PkLYGWAMkT6u4HPhhGWUzcYzDXHA7jiGEWCGlPKJ9rwNmtRFjIXnVAXNSyuDSvJcTOjoFtZH9cpTdDAynUEVmlM2EiVwwna8JEyZMVADmtIOJExpCCIsQImuwUa6FylLkYeLEg+l8jxO47BZdekOL3ZWV4tDicOlSHFocrrT8XDZLTspEl91SMspEPRmMyGFEBrvNOiGEkEAciGbVy+YML71mdy7Y1UgeQFoei/NLp/M0cXzDnHY4TiCEkL1Xb+GWR4foDLjwOa2Eogku/eEuei6/FldDJ1a3j0QkhIxFqVqrNj7suKINKWXa9ikhhFx6365rLkWvjGhcsrlLUT22XbVDN79CddpyXS9D225Jk+PaV/UUJYMQQo798jOG5Kh97X+k2XDXNZfymTvHildSw3+8oLZkdjNxbMDkdjiO8MDBKbwOK1LCdCg+z87lauxSTGPag9bV3EN4vJ/oVPZj3Jbel6mMWELyRN8Mp7b6Sq7T1O4HsDq9ICXxuel51rKugIvh2ei8aD31LvqnwoRjxQ0mbrrrcbqaavC7nQQjMZK7evVskQmP33ETNS1dOL1+YuEgCIHLW40n0IDbX1OUfCaOH5jO9zjCOZ1VuterVp+je90ZaMman959mcpoqdIn5SkWmWTPJEex6G4KMLSItrI2qxx6CLR2Mzs+NO+oa9tXkYjHmBrqNZ2viXmY0w7HCVx2y0A4JtNJXqx2iEcz3pfpxAlhc4wSj9amXst26sN8mhKezmBxuAZkNJymk90C0SznCRuRIZ9ph553fovxyXQKSHPawUQxMJ3vcQwhREBKOZ76Xe9aoXll+14ulEont8M+EIrmx0iWCqvdSTwazp3QIGwO12A0HDTZzk4gmM7XhIkl0IIpngI+CrxUSvk67Xo+D6s3Aa9CHYNxm5Ty+uV4OJk4dmBuNTNhIh1JNridwCnJi3k6ziTD2f3a93zvN3Gcw3S+Jkyk4wwUO9mTQJcQopAD1xaxoZVQNhPHCUzna8JEOjai2MkiwDMoHmPD0BjOkqPnR4ENFSAhMnGUw2wQJkykQAsDfg2KRhLAjWI2ywcvB6qllINSyjEtj9eWTkoTxwPMfb4mTCxGFLgbNWUAcD2Q7xawI6ijm5L4LbCveNFMHE8wdzuYMGHCRAVgTjuYMGHCRAVgOl8TJkyYqABM52vihEYpqDhLTedp4sSAOedr4oRGkopzKdqu2sGW63oz3pdKxVmKPEyceDB3O5g44fHAwSmGZ6PUeewA81ScU7sfIDo5jN2vToB3NfcgEzFisxNF55GLztPE8Q/T+Zo44RGXkg2tPvqnwngcVmIJ9TboDLQCAqvLg81XS3j4IBa7C1tVXVoerdVOhACPw0qtx8ZEMJYxD2G1Ya8pmNPHxHECc9rBxAmNTFScwuZExjKzlqVScZYiDxMnHkzna8KECRMVgLnbwYQJEyYqANP5mjBhwkQFYDpfEyZMmKgATOdrwoQJExWA6XxNmDBhogIwna8JEyZMVACm8zVhwoSJCsB0viZMmDBRAZjO14QJEyYqANP5mjBhwkQF8P8BG7csUOzG4qIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Drow a tree \n",
    "from sklearn import tree\n",
    "\n",
    "#plt.figure(figsize=(30,30))\n",
    "f = x.columns\n",
    "_ = tree.plot_tree(dtc,feature_names=f,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d732b6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       404\n",
      "           1       0.58      0.68      0.62       196\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.70      0.72      0.71       600\n",
      "weighted avg       0.75      0.73      0.74       600\n",
      "\n",
      "[[305  99]\n",
      " [ 62 134]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84       404\n",
      "           1       0.74      0.39      0.51       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.66      0.68       600\n",
      "weighted avg       0.75      0.76      0.73       600\n",
      "\n",
      "[[377  27]\n",
      " [119  77]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       404\n",
      "           1       0.67      0.65      0.66       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[342  62]\n",
      " [ 69 127]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       404\n",
      "           1       0.68      0.70      0.69       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.77      0.77       600\n",
      "weighted avg       0.80      0.79      0.79       600\n",
      "\n",
      "[[339  65]\n",
      " [ 59 137]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       404\n",
      "           1       0.72      0.73      0.73       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.79      0.80      0.80       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n",
      "[[348  56]\n",
      " [ 52 144]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       404\n",
      "           1       0.76      0.77      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.83      0.82       600\n",
      "weighted avg       0.85      0.84      0.85       600\n",
      "\n",
      "[[356  48]\n",
      " [ 45 151]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       404\n",
      "           1       0.80      0.81      0.81       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.86      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[364  40]\n",
      " [ 37 159]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       404\n",
      "           1       0.82      0.82      0.82       196\n",
      "\n",
      "    accuracy                           0.88       600\n",
      "   macro avg       0.86      0.86      0.86       600\n",
      "weighted avg       0.88      0.88      0.88       600\n",
      "\n",
      "[[368  36]\n",
      " [ 36 160]]\n"
     ]
    }
   ],
   "source": [
    "#We get recall score 0.94(94%) which is good , but we can do better\n",
    "#So we apply pruning technique on DecisionTreeClassifier. There are 2 types of pruning tech.\n",
    "#1.Max Depth : between >=1 to <=8 we apply for-loop\n",
    "for i in range(1,9):\n",
    "    #create an object for DecisionTreeClassifier class with max_depth\n",
    "    dtc1 = DecisionTreeClassifier(random_state=1,max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call the function\n",
    "    dtc1 = create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fe4d085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       404\n",
      "           1       0.82      0.82      0.82       196\n",
      "\n",
      "    accuracy                           0.88       600\n",
      "   macro avg       0.86      0.86      0.86       600\n",
      "weighted avg       0.88      0.88      0.88       600\n",
      "\n",
      "[[368  36]\n",
      " [ 36 160]]\n"
     ]
    }
   ],
   "source": [
    "#got the best score at 8\n",
    "dtc1 = DecisionTreeClassifier(random_state=1,max_depth=8)\n",
    "#call the function\n",
    "dtc1 = create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1c4d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.398938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.205352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.116131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.097225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.070877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.065083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.046393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.398938\n",
       "1                       BMI  0.205352\n",
       "2  DiabetesPedigreeFunction  0.116131\n",
       "3               Pregnancies  0.097225\n",
       "4                   Insulin  0.070877\n",
       "5             BloodPressure  0.065083\n",
       "6             SkinThickness  0.046393"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict2 = {\"Input\":x.columns,\"IG\":dtc1.feature_importances_}\n",
    "df3 = pd.DataFrame(dict2)\n",
    "df3.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4bd1fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Sample Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       404\n",
      "           1       0.67      0.65      0.66       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[342  62]\n",
      " [ 68 128]]\n",
      "Min Sample Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       404\n",
      "           1       0.67      0.65      0.66       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[342  62]\n",
      " [ 68 128]]\n",
      "Min Sample Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       404\n",
      "           1       0.67      0.65      0.66       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[342  62]\n",
      " [ 68 128]]\n",
      "Min Sample Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       404\n",
      "           1       0.67      0.65      0.66       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[342  62]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 69 127]]\n",
      "Min Sample Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       404\n",
      "           1       0.74      0.60      0.66       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.75      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[363  41]\n",
      " [ 78 118]]\n",
      "Min Sample Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[359  45]\n",
      " [ 72 124]]\n",
      "Min Sample Leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.64      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[358  46]\n",
      " [ 71 125]]\n",
      "Min Sample Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.73      0.64      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[358  46]\n",
      " [ 71 125]]\n",
      "Min Sample Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       404\n",
      "           1       0.73      0.64      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[358  46]\n",
      " [ 70 126]]\n",
      "Min Sample Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       404\n",
      "           1       0.74      0.63      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[361  43]\n",
      " [ 73 123]]\n",
      "Min Sample Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       404\n",
      "           1       0.73      0.64      0.68       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[358  46]\n",
      " [ 70 126]]\n",
      "Min Sample Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.69      0.68       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.76      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[336  68]\n",
      " [ 61 135]]\n",
      "Min Sample Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       404\n",
      "           1       0.66      0.68      0.67       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[336  68]\n",
      " [ 63 133]]\n",
      "Min Sample Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       404\n",
      "           1       0.62      0.79      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.78      0.76       600\n",
      "weighted avg       0.80      0.77      0.78       600\n",
      "\n",
      "[[308  96]\n",
      " [ 41 155]]\n",
      "Min Sample Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       404\n",
      "           1       0.62      0.79      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.78      0.76       600\n",
      "weighted avg       0.80      0.77      0.78       600\n",
      "\n",
      "[[308  96]\n",
      " [ 41 155]]\n",
      "Min Sample Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       404\n",
      "           1       0.62      0.79      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.78      0.76       600\n",
      "weighted avg       0.80      0.77      0.78       600\n",
      "\n",
      "[[308  96]\n",
      " [ 41 155]]\n",
      "Min Sample Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       404\n",
      "           1       0.62      0.79      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.78      0.76       600\n",
      "weighted avg       0.80      0.77      0.78       600\n",
      "\n",
      "[[308  96]\n",
      " [ 41 155]]\n"
     ]
    }
   ],
   "source": [
    "#2.Mim Sample Leaf : between >=45 to <=100, so apply for-loop\n",
    "for i in range(45,101):\n",
    "    #create an object for DecisionTreeClassifier class with min_samples_leaf\n",
    "    dtc2 = DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min Sample Leaf:\",i)\n",
    "    #call the function\n",
    "    dtc2 = create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16f93480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82       404\n",
      "           1       0.62      0.79      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.78      0.76       600\n",
      "weighted avg       0.80      0.77      0.78       600\n",
      "\n",
      "[[308  96]\n",
      " [ 41 155]]\n"
     ]
    }
   ],
   "source": [
    "#Got the best score at 97\n",
    "dtc2 = DecisionTreeClassifier(random_state=1,min_samples_leaf=97)\n",
    "#call function\n",
    "dtc2 = create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3708f3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.743106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.184024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.059875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.007461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.005533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.743106\n",
       "1                       BMI  0.184024\n",
       "2               Pregnancies  0.059875\n",
       "3  DiabetesPedigreeFunction  0.007461\n",
       "4                   Insulin  0.005533\n",
       "5             BloodPressure  0.000000\n",
       "6             SkinThickness  0.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict3 = {\"Input\":x.columns,\"IG\":dtc2.feature_importances_}\n",
    "df4 = pd.DataFrame(dict3)\n",
    "df4.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba951cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n"
     ]
    }
   ],
   "source": [
    "#2. Applying Decision Tree with Entropy Index\n",
    "#create an object for DecisionTreeClassifier class with Entropy index\n",
    "dtc_entropy = DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "#call the function\n",
    "dtc_entropy = create_model(dtc_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Got the recall score 0.95(95%) on Decision Tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab49a39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.295656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.227256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.127263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.104600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.088460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.084155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.072610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.295656\n",
       "1                       BMI  0.227256\n",
       "2  DiabetesPedigreeFunction  0.127263\n",
       "3               Pregnancies  0.104600\n",
       "4             BloodPressure  0.088460\n",
       "5                   Insulin  0.084155\n",
       "6             SkinThickness  0.072610"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict4 = {\"Input\":x.columns,\"IG\":dtc_entropy.feature_importances_}\n",
    "df5 = pd.DataFrame(dict4)\n",
    "df5.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f299f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw a tree\n",
    "\n",
    "f = x.columns\n",
    "_ = tree.plot_tree(dtc_entropy,feature_names=f,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0eeeeabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.76       404\n",
      "           1       0.54      0.73      0.62       196\n",
      "\n",
      "    accuracy                           0.71       600\n",
      "   macro avg       0.69      0.72      0.69       600\n",
      "weighted avg       0.75      0.71      0.72       600\n",
      "\n",
      "[[282 122]\n",
      " [ 52 144]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84       404\n",
      "           1       0.74      0.39      0.51       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.66      0.68       600\n",
      "weighted avg       0.75      0.76      0.73       600\n",
      "\n",
      "[[377  27]\n",
      " [119  77]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       404\n",
      "           1       0.59      0.71      0.65       196\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.72      0.74      0.73       600\n",
      "weighted avg       0.76      0.75      0.75       600\n",
      "\n",
      "[[308  96]\n",
      " [ 56 140]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       404\n",
      "           1       0.75      0.47      0.58       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.70      0.71       600\n",
      "weighted avg       0.77      0.78      0.76       600\n",
      "\n",
      "[[373  31]\n",
      " [104  92]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81       404\n",
      "           1       0.61      0.80      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.77      0.75       600\n",
      "weighted avg       0.79      0.77      0.77       600\n",
      "\n",
      "[[304 100]\n",
      " [ 40 156]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.66      0.70       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.77      0.78       600\n",
      "weighted avg       0.81      0.81      0.81       600\n",
      "\n",
      "[[357  47]\n",
      " [ 66 130]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       404\n",
      "           1       0.76      0.68      0.72       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.79      0.80       600\n",
      "weighted avg       0.82      0.83      0.82       600\n",
      "\n",
      "[[362  42]\n",
      " [ 62 134]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.76      0.72      0.74       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.81      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[360  44]\n",
      " [ 55 141]]\n"
     ]
    }
   ],
   "source": [
    "#Now apply Pruning technique on DecisionTreeClassifier with entropy index\n",
    "#1.max_depth on entropy index : between >=1 to <=8 aplly for-loop\n",
    "#create an object for DecisionTreeClassifier class \n",
    "for i in range(1,9):\n",
    "    dtc_entropy1 = DecisionTreeClassifier(random_state=1,criterion='entropy',max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    dtc_entropy1 = create_model(dtc_entropy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79dd3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81       404\n",
      "           1       0.61      0.80      0.69       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.77      0.75       600\n",
      "weighted avg       0.79      0.77      0.77       600\n",
      "\n",
      "[[304 100]\n",
      " [ 40 156]]\n"
     ]
    }
   ],
   "source": [
    "#we got best score at 5\n",
    "dtc_entropy1 = DecisionTreeClassifier(random_state=1,criterion='entropy',max_depth=5)\n",
    "#call function\n",
    "dtc_entropy1 = create_model(dtc_entropy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b53c739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.496207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.236714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.109594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.096041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.036625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.024820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.496207\n",
       "1                       BMI  0.236714\n",
       "2               Pregnancies  0.109594\n",
       "3  DiabetesPedigreeFunction  0.096041\n",
       "4                   Insulin  0.036625\n",
       "5             SkinThickness  0.024820\n",
       "6             BloodPressure  0.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict5 = {\"Input\":x.columns,\"IG\":dtc_entropy1.feature_importances_}\n",
    "df6 = pd.DataFrame(dict5)\n",
    "df6.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9ec8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       404\n",
      "           1       0.69      0.63      0.66       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[348  56]\n",
      " [ 73 123]]\n",
      "Min Samples Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       404\n",
      "           1       0.72      0.56      0.63       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[362  42]\n",
      " [ 87 109]]\n",
      "Min Samples Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       404\n",
      "           1       0.71      0.58      0.64       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[358  46]\n",
      " [ 82 114]]\n",
      "Min Samples Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       404\n",
      "           1       0.68      0.63      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[347  57]\n",
      " [ 73 123]]\n",
      "Min Samples Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       404\n",
      "           1       0.71      0.58      0.64       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[358  46]\n",
      " [ 82 114]]\n",
      "Min Samples Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       404\n",
      "           1       0.69      0.62      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[349  55]\n",
      " [ 75 121]]\n",
      "Min Samples Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.68      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       404\n",
      "           1       0.65      0.62      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.77      0.77       600\n",
      "\n",
      "[[339  65]\n",
      " [ 75 121]]\n",
      "Min Samples Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.65      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.77      0.77       600\n",
      "\n",
      "[[337  67]\n",
      " [ 73 123]]\n",
      "Min Samples Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.65      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[337  67]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.65      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[337  67]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.65      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[337  67]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       404\n",
      "           1       0.65      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[335  69]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.64      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[335  69]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83       404\n",
      "           1       0.64      0.63      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[335  69]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.55      0.61       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.71      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[351  53]\n",
      " [ 88 108]]\n",
      "Min Samples Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.55      0.61       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.71      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[351  53]\n",
      " [ 88 108]]\n",
      "Min Samples Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       404\n",
      "           1       0.70      0.59      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[355  49]\n",
      " [ 81 115]]\n",
      "Min Samples Leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.71      0.69       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.77      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[335  69]\n",
      " [ 57 139]]\n",
      "Min Samples Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.71      0.69       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.77      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[335  69]\n",
      " [ 57 139]]\n",
      "Min Samples Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.71      0.69       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.77      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[335  69]\n",
      " [ 57 139]]\n",
      "Min Samples Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       404\n",
      "           1       0.66      0.61      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[343  61]\n",
      " [ 77 119]]\n",
      "Min Samples Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       404\n",
      "           1       0.66      0.61      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[343  61]\n",
      " [ 77 119]]\n",
      "Min Samples Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       404\n",
      "           1       0.66      0.61      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[343  61]\n",
      " [ 77 119]]\n",
      "Min Samples Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       404\n",
      "           1       0.62      0.64      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.73      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[327  77]\n",
      " [ 70 126]]\n",
      "Min Samples Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n",
      "Min Samples Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.64      0.64       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[332  72]\n",
      " [ 71 125]]\n"
     ]
    }
   ],
   "source": [
    "#2.Pruning tech. min_samples_leaf : between >=45 to <=100 we apply for-loop\n",
    "for i in range(45,101):\n",
    "    dtc_entropy2 = DecisionTreeClassifier(random_state=1,criterion='entropy',min_samples_leaf=i)\n",
    "    print(\"Min Samples Leaf:\",i)\n",
    "    #call function\n",
    "    dtc_entropy2 = create_model(dtc_entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c155680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       404\n",
      "           1       0.67      0.71      0.69       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.77      0.76       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[335  69]\n",
      " [ 57 139]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 74\n",
    "dtc_entropy2 = DecisionTreeClassifier(random_state=1,criterion='entropy',min_samples_leaf=74)\n",
    "#call function\n",
    "dtc_entropy2 = create_model(dtc_entropy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cad4debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.682007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.208931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.079358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.017622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.012082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.682007\n",
       "1                       BMI  0.208931\n",
       "2               Pregnancies  0.079358\n",
       "3  DiabetesPedigreeFunction  0.017622\n",
       "4                   Insulin  0.012082\n",
       "5             BloodPressure  0.000000\n",
       "6             SkinThickness  0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict6 = {\"Input\":x.columns,\"IG\":dtc_entropy2.feature_importances_}\n",
    "df7 = pd.DataFrame(dict6)\n",
    "df7.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02441228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd classification is Random Forest classifier by default it takes GINI Index\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e947b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[391  13]\n",
      " [  8 188]]\n",
      "No. of Estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[391  13]\n",
      " [  8 188]]\n",
      "No. of Estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[393  11]\n",
      " [ 10 186]]\n",
      "No. of Estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[391  13]\n",
      " [  6 190]]\n",
      "No. of Estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 12 184]]\n",
      "No. of Estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  6 190]]\n",
      "No. of Estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       404\n",
      "           1       0.95      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[394  10]\n",
      " [  6 190]]\n",
      "No. of Estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  6 190]]\n",
      "No. of Estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       404\n",
      "           1       0.97      0.97      0.97       196\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.98      0.98      0.98       600\n",
      "weighted avg       0.98      0.98      0.98       600\n",
      "\n",
      "[[398   6]\n",
      " [  6 190]]\n",
      "No. of Estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  6 190]]\n",
      "No. of Estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       404\n",
      "           1       0.96      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.97      0.97      0.97       600\n",
      "weighted avg       0.98      0.98      0.98       600\n",
      "\n",
      "[[396   8]\n",
      " [  6 190]]\n",
      "No. of Estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  6 190]]\n",
      "No. of Estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       404\n",
      "           1       0.95      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[394  10]\n",
      " [  6 190]]\n",
      "No. of Estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.97      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[387  17]\n",
      " [  4 192]]\n",
      "No. of Estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[388  16]\n",
      " [  6 190]]\n",
      "No. of Estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[388  16]\n",
      " [  6 190]]\n",
      "No. of Estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[388  16]\n",
      " [  6 190]]\n",
      "No. of Estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       404\n",
      "           1       0.93      0.98      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  4 192]]\n",
      "No. of Estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       404\n",
      "           1       0.92      0.98      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[388  16]\n",
      " [  4 192]]\n",
      "No. of Estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       404\n",
      "           1       0.95      0.97      0.96       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[394  10]\n",
      " [  6 190]]\n",
      "No. of Estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       404\n",
      "           1       0.94      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.97       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  6 190]]\n",
      "No. of Estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.93      0.97      0.95       196\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.97      0.96       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "[[390  14]\n",
      " [  6 190]]\n",
      "No. of Estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.97      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  6 190]]\n",
      "No. of Estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n",
      "No. of Estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n",
      "No. of Estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n",
      "No. of Estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n",
      "No. of Estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.92      0.95      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[387  17]\n",
      " [  9 187]]\n",
      "No. of Estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.95      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[392  12]\n",
      " [  9 187]]\n",
      "No. of Estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  7 189]]\n",
      "No. of Estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n",
      "No. of Estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       404\n",
      "           1       0.93      0.95      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.96      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[389  15]\n",
      " [  9 187]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for RandomForestClassifier class\n",
    "#it takes n_estimators means number of Iteration means no. of Decision tree\n",
    "#n_estimators take >=10 and <=100\n",
    "for i in range(10,101):\n",
    "    rfc = RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    rfc = create_model(rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "526873a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       404\n",
      "           1       0.94      0.96      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.97      0.96      0.97       600\n",
      "\n",
      "[[391  13]\n",
      " [  8 188]]\n"
     ]
    }
   ],
   "source": [
    "#Got best score at 10\n",
    "rfc = RandomForestClassifier(n_estimators=10,random_state=1)\n",
    "#call function\n",
    "rfc = create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef737286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.278362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.177534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.160665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.116945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.097770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.085571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.083152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.278362\n",
       "1                       BMI  0.177534\n",
       "2  DiabetesPedigreeFunction  0.160665\n",
       "3               Pregnancies  0.116945\n",
       "4             BloodPressure  0.097770\n",
       "5                   Insulin  0.085571\n",
       "6             SkinThickness  0.083152"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict7 = {\"Input\":x.columns,\"IG\":rfc.feature_importances_}\n",
    "df8 = pd.DataFrame(dict7)\n",
    "df8.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d3593be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.99      0.82       404\n",
      "           1       0.86      0.10      0.17       196\n",
      "\n",
      "    accuracy                           0.70       600\n",
      "   macro avg       0.78      0.54      0.50       600\n",
      "weighted avg       0.75      0.70      0.61       600\n",
      "\n",
      "[[401   3]\n",
      " [177  19]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.83       404\n",
      "           1       0.76      0.24      0.36       196\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.60      0.60       600\n",
      "weighted avg       0.73      0.73      0.68       600\n",
      "\n",
      "[[389  15]\n",
      " [149  47]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       404\n",
      "           1       0.78      0.41      0.54       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.77      0.68      0.69       600\n",
      "weighted avg       0.77      0.77      0.75       600\n",
      "\n",
      "[[381  23]\n",
      " [115  81]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       404\n",
      "           1       0.75      0.58      0.65       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.74      0.75       600\n",
      "weighted avg       0.79      0.80      0.79       600\n",
      "\n",
      "[[366  38]\n",
      " [ 83 113]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       404\n",
      "           1       0.81      0.64      0.72       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.83      0.78      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[374  30]\n",
      " [ 70 126]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       404\n",
      "           1       0.80      0.71      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.84      0.82      0.82       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[370  34]\n",
      " [ 56 140]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       404\n",
      "           1       0.84      0.72      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.86      0.83      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[378  26]\n",
      " [ 55 141]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       404\n",
      "           1       0.88      0.79      0.83       196\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.89      0.87      0.88       600\n",
      "weighted avg       0.89      0.90      0.89       600\n",
      "\n",
      "[[382  22]\n",
      " [ 41 155]]\n"
     ]
    }
   ],
   "source": [
    "#Got the best recall score of 0.96(96%) which is best score\n",
    "#Now apply pruning technique on RandomForestClassifier class\n",
    "#1.Max Depth : between >=1 to <=8 apply for-loop\n",
    "for i in range(1,9):\n",
    "    rfc1 = RandomForestClassifier(n_estimators=10,random_state=1,max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bd265c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       404\n",
      "           1       0.88      0.79      0.83       196\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.89      0.87      0.88       600\n",
      "weighted avg       0.89      0.90      0.89       600\n",
      "\n",
      "[[382  22]\n",
      " [ 41 155]]\n"
     ]
    }
   ],
   "source": [
    "#Got the good score at 8\n",
    "rfc1 = RandomForestClassifier(n_estimators=10,random_state=1,max_depth=8)\n",
    "#call function\n",
    "rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96058a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.276148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.192997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.147495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.114918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.095637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.086641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.086164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.276148\n",
       "1                       BMI  0.192997\n",
       "2  DiabetesPedigreeFunction  0.147495\n",
       "3               Pregnancies  0.114918\n",
       "4                   Insulin  0.095637\n",
       "5             SkinThickness  0.086641\n",
       "6             BloodPressure  0.086164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict8 = {\"Input\":x.columns,\"IG\":rfc1.feature_importances_}\n",
    "df9 = pd.DataFrame(dict8)\n",
    "df9.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dd1a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       404\n",
      "           1       0.71      0.61      0.65       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.77      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.79       600\n",
      "\n",
      "[[355  49]\n",
      " [ 77 119]]\n",
      "Min Samples Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       404\n",
      "           1       0.70      0.60      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.74      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[353  51]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       404\n",
      "           1       0.69      0.57      0.62       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[353  51]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       404\n",
      "           1       0.69      0.58      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.73       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[352  52]\n",
      " [ 82 114]]\n",
      "Min Samples Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       404\n",
      "           1       0.68      0.57      0.62       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[352  52]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       404\n",
      "           1       0.68      0.58      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.73       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[351  53]\n",
      " [ 82 114]]\n",
      "Min Samples Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       404\n",
      "           1       0.67      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[346  58]\n",
      " [ 78 118]]\n",
      "Min Samples Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       404\n",
      "           1       0.67      0.62      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[345  59]\n",
      " [ 75 121]]\n",
      "Min Samples Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       404\n",
      "           1       0.67      0.61      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[345  59]\n",
      " [ 76 120]]\n",
      "Min Samples Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       404\n",
      "           1       0.67      0.60      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[346  58]\n",
      " [ 79 117]]\n",
      "Min Samples Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       404\n",
      "           1       0.67      0.62      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.77      0.78      0.78       600\n",
      "\n",
      "[[345  59]\n",
      " [ 74 122]]\n",
      "Min Samples Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       404\n",
      "           1       0.69      0.63      0.66       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.75      0.75       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[348  56]\n",
      " [ 72 124]]\n",
      "Min Samples Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       404\n",
      "           1       0.68      0.63      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[346  58]\n",
      " [ 73 123]]\n",
      "Min Samples Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       404\n",
      "           1       0.68      0.63      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[346  58]\n",
      " [ 73 123]]\n",
      "Min Samples Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       404\n",
      "           1       0.67      0.62      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[344  60]\n",
      " [ 74 122]]\n",
      "Min Samples Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       404\n",
      "           1       0.71      0.61      0.66       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.79       600\n",
      "\n",
      "[[354  50]\n",
      " [ 76 120]]\n",
      "Min Samples Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       404\n",
      "           1       0.70      0.61      0.65       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[354  50]\n",
      " [ 77 119]]\n",
      "Min Samples Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       404\n",
      "           1       0.69      0.62      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.74      0.75       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[348  56]\n",
      " [ 74 122]]\n",
      "Min Samples Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       404\n",
      "           1       0.66      0.62      0.64       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[341  63]\n",
      " [ 75 121]]\n",
      "Min Samples Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       404\n",
      "           1       0.69      0.61      0.65       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[349  55]\n",
      " [ 76 120]]\n",
      "Min Samples Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.67      0.59      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 80 116]]\n",
      "Min Samples Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.67      0.59      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[348  56]\n",
      " [ 80 116]]\n",
      "Min Samples Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       404\n",
      "           1       0.68      0.60      0.64       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[349  55]\n",
      " [ 78 118]]\n",
      "Min Samples Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       404\n",
      "           1       0.69      0.57      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354  50]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       404\n",
      "           1       0.69      0.57      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[354  50]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84       404\n",
      "           1       0.67      0.59      0.63       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[347  57]\n",
      " [ 80 116]]\n",
      "Min Samples Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       404\n",
      "           1       0.67      0.58      0.62       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.72      0.73       600\n",
      "weighted avg       0.76      0.77      0.77       600\n",
      "\n",
      "[[349  55]\n",
      " [ 83 113]]\n",
      "Min Samples Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       404\n",
      "           1       0.70      0.57      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[357  47]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       404\n",
      "           1       0.70      0.57      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.73      0.74       600\n",
      "weighted avg       0.78      0.78      0.78       600\n",
      "\n",
      "[[357  47]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       404\n",
      "           1       0.69      0.56      0.62       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.77      0.77      0.77       600\n",
      "\n",
      "[[354  50]\n",
      " [ 86 110]]\n",
      "Min Samples Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       404\n",
      "           1       0.69      0.56      0.61       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.72      0.73       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[354  50]\n",
      " [ 87 109]]\n",
      "Min Samples Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       404\n",
      "           1       0.67      0.57      0.62       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.72      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[348  56]\n",
      " [ 84 112]]\n",
      "Min Samples Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       404\n",
      "           1       0.66      0.56      0.61       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.71      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[349  55]\n",
      " [ 87 109]]\n",
      "Min Samples Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[351  53]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[351  53]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[351  53]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[351  53]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       404\n",
      "           1       0.67      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[351  53]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       404\n",
      "           1       0.66      0.56      0.61       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.71      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[348  56]\n",
      " [ 86 110]]\n",
      "Min Samples Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       404\n",
      "           1       0.69      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.71      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[356  48]\n",
      " [ 91 105]]\n",
      "Min Samples Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83       404\n",
      "           1       0.68      0.54      0.60       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.71      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[354  50]\n",
      " [ 90 106]]\n",
      "Min Samples Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.84       404\n",
      "           1       0.68      0.53      0.60       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.71      0.72       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[356  48]\n",
      " [ 92 104]]\n",
      "Min Samples Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       404\n",
      "           1       0.71      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[363  41]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       404\n",
      "           1       0.71      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[363  41]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       404\n",
      "           1       0.71      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[363  41]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       404\n",
      "           1       0.70      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[362  42]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84       404\n",
      "           1       0.72      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.76      0.71      0.72       600\n",
      "weighted avg       0.77      0.78      0.76       600\n",
      "\n",
      "[[366  38]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       404\n",
      "           1       0.68      0.49      0.57       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.69      0.70       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[358  46]\n",
      " [ 99  97]]\n",
      "Min Samples Leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       404\n",
      "           1       0.68      0.49      0.57       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.69      0.70       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[358  46]\n",
      " [ 99  97]]\n",
      "Min Samples Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       404\n",
      "           1       0.67      0.49      0.57       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.69      0.70       600\n",
      "weighted avg       0.75      0.76      0.74       600\n",
      "\n",
      "[[356  48]\n",
      " [ 99  97]]\n",
      "Min Samples Leaf: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       404\n",
      "           1       0.67      0.49      0.56       196\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.72      0.69      0.70       600\n",
      "weighted avg       0.74      0.75      0.74       600\n",
      "\n",
      "[[356  48]\n",
      " [100  96]]\n",
      "Min Samples Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       404\n",
      "           1       0.68      0.49      0.57       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.69      0.70       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[359  45]\n",
      " [100  96]]\n",
      "Min Samples Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       404\n",
      "           1       0.70      0.51      0.59       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.75      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.76       600\n",
      "\n",
      "[[362  42]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       404\n",
      "           1       0.69      0.51      0.58       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.70      0.71       600\n",
      "weighted avg       0.76      0.77      0.75       600\n",
      "\n",
      "[[360  44]\n",
      " [ 97  99]]\n",
      "Min Samples Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       404\n",
      "           1       0.68      0.50      0.57       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.69      0.70       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[357  47]\n",
      " [ 98  98]]\n",
      "Min Samples Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83       404\n",
      "           1       0.68      0.51      0.58       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.73      0.70      0.71       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "[[358  46]\n",
      " [ 97  99]]\n"
     ]
    }
   ],
   "source": [
    "#Applying 2nd pruning technique Min Samples Leaf between >=45 to <=100 apply for-loop\n",
    "for i in range(45,101):\n",
    "    rfc2 = RandomForestClassifier(n_estimators=10,random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min Samples Leaf:\",i)\n",
    "    #call function\n",
    "    rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "257a7372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       404\n",
      "           1       0.71      0.61      0.65       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.77      0.74      0.75       600\n",
      "weighted avg       0.78      0.79      0.79       600\n",
      "\n",
      "[[355  49]\n",
      " [ 77 119]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 45\n",
    "rfc2 = RandomForestClassifier(n_estimators=10,random_state=1,min_samples_leaf=45)\n",
    "#call function\n",
    "rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cd0ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.446146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.138086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.132725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.109082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.084356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.047646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.041959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.446146\n",
       "1                       BMI  0.138086\n",
       "2               Pregnancies  0.132725\n",
       "3  DiabetesPedigreeFunction  0.109082\n",
       "4                   Insulin  0.084356\n",
       "5             BloodPressure  0.047646\n",
       "6             SkinThickness  0.041959"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict9 = {\"Input\":x.columns,\"IG\":rfc2.feature_importances_}\n",
    "df10 = pd.DataFrame(dict9)\n",
    "df10.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4127f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Applying Boosting technique :\n",
    "#1.ADA Boost : means Adaptor Boosting call the inbuilt class \n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f607a603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       404\n",
      "           1       0.58      0.68      0.62       196\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.70      0.72      0.71       600\n",
      "weighted avg       0.75      0.73      0.74       600\n",
      "\n",
      "[[305  99]\n",
      " [ 62 134]]\n",
      "No. of Estimators: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.63      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.72      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[330  74]\n",
      " [ 72 124]]\n",
      "No. of Estimators: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       404\n",
      "           1       0.63      0.63      0.63       196\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.72      0.72      0.72       600\n",
      "weighted avg       0.76      0.76      0.76       600\n",
      "\n",
      "[[330  74]\n",
      " [ 72 124]]\n",
      "No. of Estimators: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       404\n",
      "           1       0.62      0.72      0.67       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.76      0.74       600\n",
      "weighted avg       0.78      0.77      0.77       600\n",
      "\n",
      "[[318  86]\n",
      " [ 54 142]]\n",
      "No. of Estimators: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       404\n",
      "           1       0.64      0.68      0.66       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.75      0.74       600\n",
      "weighted avg       0.78      0.77      0.77       600\n",
      "\n",
      "[[330  74]\n",
      " [ 63 133]]\n",
      "No. of Estimators: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       404\n",
      "           1       0.64      0.69      0.66       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.75      0.75       600\n",
      "weighted avg       0.78      0.77      0.77       600\n",
      "\n",
      "[[328  76]\n",
      " [ 61 135]]\n",
      "No. of Estimators: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       404\n",
      "           1       0.63      0.71      0.67       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.76      0.75       600\n",
      "weighted avg       0.78      0.77      0.77       600\n",
      "\n",
      "[[322  82]\n",
      " [ 56 140]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for AdaBoostClassifier class\n",
    "#AdaBoostClassifier class as n_estimators means how many decision stump , \n",
    "#decision stump depends on number of inputs=7 , we aplly for-loop\n",
    "for i in range(1,8):\n",
    "    ada = AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e60b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       404\n",
      "           1       0.62      0.72      0.67       196\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.74      0.76      0.74       600\n",
      "weighted avg       0.78      0.77      0.77       600\n",
      "\n",
      "[[318  86]\n",
      " [ 54 142]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 4\n",
    "ada = AdaBoostClassifier(n_estimators=4,random_state=1)\n",
    "#call function\n",
    "ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bc5e370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input    IG\n",
       "0                   Glucose  0.50\n",
       "1               Pregnancies  0.25\n",
       "2                       BMI  0.25\n",
       "3             BloodPressure  0.00\n",
       "4             SkinThickness  0.00\n",
       "5                   Insulin  0.00\n",
       "6  DiabetesPedigreeFunction  0.00"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict10 = {\"Input\":x.columns,\"IG\":ada.feature_importances_}\n",
    "df11 = pd.DataFrame(dict10)\n",
    "df11.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff83243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Gradient Boosting : call inbuilt function\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2da1b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       404\n",
      "           1       0.74      0.53      0.62       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.77      0.72      0.74       600\n",
      "weighted avg       0.78      0.79      0.78       600\n",
      "\n",
      "[[368  36]\n",
      " [ 92 104]]\n",
      "No. of Estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.85       404\n",
      "           1       0.73      0.58      0.65       196\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.77      0.74      0.75       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "[[362  42]\n",
      " [ 82 114]]\n",
      "No. of Estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       404\n",
      "           1       0.70      0.67      0.69       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.77      0.77      0.77       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[349  55]\n",
      " [ 65 131]]\n",
      "No. of Estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       404\n",
      "           1       0.71      0.67      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.78       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[351  53]\n",
      " [ 64 132]]\n",
      "No. of Estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       404\n",
      "           1       0.75      0.61      0.67       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.76      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[364  40]\n",
      " [ 76 120]]\n",
      "No. of Estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       404\n",
      "           1       0.71      0.67      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.78       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[351  53]\n",
      " [ 64 132]]\n",
      "No. of Estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.66      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[354  50]\n",
      " [ 67 129]]\n",
      "No. of Estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       404\n",
      "           1       0.70      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.77      0.76      0.76       600\n",
      "weighted avg       0.79      0.80      0.79       600\n",
      "\n",
      "[[350  54]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       404\n",
      "           1       0.70      0.65      0.68       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.77      0.76      0.76       600\n",
      "weighted avg       0.79      0.80      0.79       600\n",
      "\n",
      "[[350  54]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       404\n",
      "           1       0.72      0.63      0.67       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.76      0.76       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[356  48]\n",
      " [ 72 124]]\n",
      "No. of Estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.73      0.65      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.77      0.78       600\n",
      "weighted avg       0.80      0.81      0.81       600\n",
      "\n",
      "[[357  47]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.66      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[354  50]\n",
      " [ 67 129]]\n",
      "No. of Estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.64      0.68       196\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.78      0.76      0.77       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n",
      "[[355  49]\n",
      " [ 70 126]]\n",
      "No. of Estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.65      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[355  49]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.65      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[355  49]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       404\n",
      "           1       0.72      0.65      0.69       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.77      0.77       600\n",
      "weighted avg       0.80      0.81      0.80       600\n",
      "\n",
      "[[355  49]\n",
      " [ 68 128]]\n",
      "No. of Estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       404\n",
      "           1       0.73      0.68      0.70       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.81      0.81      0.81       600\n",
      "\n",
      "[[355  49]\n",
      " [ 63 133]]\n",
      "No. of Estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       404\n",
      "           1       0.73      0.67      0.70       196\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.81      0.81      0.81       600\n",
      "\n",
      "[[356  48]\n",
      " [ 64 132]]\n",
      "No. of Estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       404\n",
      "           1       0.74      0.67      0.71       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.79      0.78      0.79       600\n",
      "weighted avg       0.81      0.82      0.81       600\n",
      "\n",
      "[[358  46]\n",
      " [ 64 132]]\n",
      "No. of Estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       404\n",
      "           1       0.74      0.68      0.71       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.80      0.78      0.79       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n",
      "[[358  46]\n",
      " [ 62 134]]\n",
      "No. of Estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[359  45]\n",
      " [ 58 138]]\n",
      "No. of Estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.69      0.72       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.80      0.79      0.80       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n",
      "[[359  45]\n",
      " [ 60 136]]\n",
      "No. of Estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[359  45]\n",
      " [ 58 138]]\n",
      "No. of Estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.69      0.72       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.80      0.79      0.80       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n",
      "[[359  45]\n",
      " [ 60 136]]\n",
      "No. of Estimators: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.72       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.79      0.80       600\n",
      "weighted avg       0.82      0.83      0.82       600\n",
      "\n",
      "[[359  45]\n",
      " [ 59 137]]\n",
      "No. of Estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.76      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[359  45]\n",
      " [ 56 140]]\n",
      "No. of Estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[359  45]\n",
      " [ 58 138]]\n",
      "No. of Estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.72       196\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.80      0.79      0.80       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n",
      "[[358  46]\n",
      " [ 59 137]]\n",
      "No. of Estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.82      0.83      0.83       600\n",
      "\n",
      "[[358  46]\n",
      " [ 58 138]]\n",
      "No. of Estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.70      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.82      0.83      0.83       600\n",
      "\n",
      "[[358  46]\n",
      " [ 58 138]]\n",
      "No. of Estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       404\n",
      "           1       0.75      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[358  46]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       404\n",
      "           1       0.76      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.80       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[359  45]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       404\n",
      "           1       0.76      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[360  44]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       404\n",
      "           1       0.76      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[360  44]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       404\n",
      "           1       0.76      0.71      0.73       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.81      0.80      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[360  44]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       404\n",
      "           1       0.77      0.71      0.74       196\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.82      0.80      0.81       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "[[362  42]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       404\n",
      "           1       0.77      0.71      0.74       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.80      0.81       600\n",
      "weighted avg       0.83      0.84      0.83       600\n",
      "\n",
      "[[363  41]\n",
      " [ 57 139]]\n",
      "No. of Estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       404\n",
      "           1       0.78      0.72      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[363  41]\n",
      " [ 54 142]]\n",
      "No. of Estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       404\n",
      "           1       0.78      0.72      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[363  41]\n",
      " [ 54 142]]\n",
      "No. of Estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.72      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.81       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 54 142]]\n",
      "No. of Estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 53 143]]\n",
      "No. of Estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 52 144]]\n",
      "No. of Estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 52 144]]\n",
      "No. of Estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[360  44]\n",
      " [ 52 144]]\n",
      "No. of Estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[360  44]\n",
      " [ 52 144]]\n",
      "No. of Estimators: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       404\n",
      "           1       0.77      0.73      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 52 144]]\n",
      "No. of Estimators: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       404\n",
      "           1       0.76      0.74      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.81      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[359  45]\n",
      " [ 51 145]]\n",
      "No. of Estimators: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       404\n",
      "           1       0.76      0.75      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[358  46]\n",
      " [ 49 147]]\n",
      "No. of Estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       404\n",
      "           1       0.76      0.75      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[358  46]\n",
      " [ 49 147]]\n",
      "No. of Estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       404\n",
      "           1       0.76      0.74      0.75       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[359  45]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.74      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.83      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[361  43]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.78      0.74      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.83      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[362  42]\n",
      " [ 51 145]]\n",
      "No. of Estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.78      0.74      0.76       196\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.83      0.82      0.82       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "[[362  42]\n",
      " [ 51 145]]\n",
      "No. of Estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.78      0.74      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.82       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[362  42]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.78      0.74      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[363  41]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.82       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[360  44]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.78      0.76      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.83      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[362  42]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.79      0.76      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[364  40]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       404\n",
      "           1       0.80      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[367  37]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.79      0.76      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[365  39]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.79      0.74      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[365  39]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.79      0.74      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[365  39]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       404\n",
      "           1       0.79      0.74      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[365  39]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       404\n",
      "           1       0.80      0.74      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[367  37]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       404\n",
      "           1       0.80      0.74      0.77       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[367  37]\n",
      " [ 50 146]]\n",
      "No. of Estimators: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       404\n",
      "           1       0.80      0.75      0.77       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[367  37]\n",
      " [ 49 147]]\n",
      "No. of Estimators: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.80      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[367  37]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.80      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[367  37]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       404\n",
      "           1       0.80      0.75      0.77       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[367  37]\n",
      " [ 49 147]]\n",
      "No. of Estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       404\n",
      "           1       0.80      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.84      0.83      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[367  37]\n",
      " [ 48 148]]\n",
      "No. of Estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.76      0.78       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 47 149]]\n",
      "No. of Estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.78      0.79       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.84      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 44 152]]\n",
      "No. of Estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.84      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 45 151]]\n",
      "No. of Estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.84      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 45 151]]\n",
      "No. of Estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.86       600\n",
      "   macro avg       0.85      0.84      0.84       600\n",
      "weighted avg       0.86      0.86      0.86       600\n",
      "\n",
      "[[369  35]\n",
      " [ 46 150]]\n",
      "No. of Estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.84      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 45 151]]\n",
      "No. of Estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       404\n",
      "           1       0.81      0.78      0.80       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.85      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 43 153]]\n",
      "No. of Estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       404\n",
      "           1       0.81      0.77      0.79       196\n",
      "\n",
      "    accuracy                           0.87       600\n",
      "   macro avg       0.85      0.84      0.85       600\n",
      "weighted avg       0.87      0.87      0.87       600\n",
      "\n",
      "[[369  35]\n",
      " [ 45 151]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for GradientBoostingClassifier class\n",
    "#it has n_estimators means how many decision tree use for train the model\n",
    "#n_estimators is >=10 and <=100 , we apply for-loop\n",
    "for i in range(10,101):\n",
    "    gbc = GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    gbc = create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1ac3ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       404\n",
      "           1       0.77      0.76      0.76       196\n",
      "\n",
      "    accuracy                           0.85       600\n",
      "   macro avg       0.83      0.82      0.83       600\n",
      "weighted avg       0.85      0.85      0.85       600\n",
      "\n",
      "[[361  43]\n",
      " [ 48 148]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 65\n",
    "gbc = GradientBoostingClassifier(n_estimators=65,random_state=1)\n",
    "#call function\n",
    "gbc = create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c3c638c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.495275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.205847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.103733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.086948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.067275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.022711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.018212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.495275\n",
       "1                       BMI  0.205847\n",
       "2  DiabetesPedigreeFunction  0.103733\n",
       "3               Pregnancies  0.086948\n",
       "4                   Insulin  0.067275\n",
       "5             BloodPressure  0.022711\n",
       "6             SkinThickness  0.018212"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict11 = {\"Input\":x.columns,\"IG\":gbc.feature_importances_}\n",
    "df12 = pd.DataFrame(dict11)\n",
    "df12.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ad01a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Extreme Gradient Boosting : XGBoost classifier\n",
    "#it is better vesion of gradient boosting , call inbuilt class\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "866b70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       404\n",
      "           1       0.82      0.80      0.81       196\n",
      "\n",
      "    accuracy                           0.88       600\n",
      "   macro avg       0.86      0.86      0.86       600\n",
      "weighted avg       0.88      0.88      0.88       600\n",
      "\n",
      "[[370  34]\n",
      " [ 39 157]]\n",
      "No. of Estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91       404\n",
      "           1       0.82      0.82      0.82       196\n",
      "\n",
      "    accuracy                           0.88       600\n",
      "   macro avg       0.87      0.87      0.87       600\n",
      "weighted avg       0.88      0.88      0.88       600\n",
      "\n",
      "[[370  34]\n",
      " [ 36 160]]\n",
      "No. of Estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       404\n",
      "           1       0.85      0.81      0.83       196\n",
      "\n",
      "    accuracy                           0.89       600\n",
      "   macro avg       0.88      0.87      0.87       600\n",
      "weighted avg       0.89      0.89      0.89       600\n",
      "\n",
      "[[375  29]\n",
      " [ 37 159]]\n",
      "No. of Estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       404\n",
      "           1       0.84      0.82      0.83       196\n",
      "\n",
      "    accuracy                           0.89       600\n",
      "   macro avg       0.88      0.87      0.87       600\n",
      "weighted avg       0.89      0.89      0.89       600\n",
      "\n",
      "[[374  30]\n",
      " [ 36 160]]\n",
      "No. of Estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       404\n",
      "           1       0.86      0.81      0.83       196\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.89      0.87      0.88       600\n",
      "weighted avg       0.89      0.90      0.89       600\n",
      "\n",
      "[[379  25]\n",
      " [ 38 158]]\n",
      "No. of Estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       404\n",
      "           1       0.86      0.81      0.83       196\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.89      0.87      0.88       600\n",
      "weighted avg       0.89      0.90      0.89       600\n",
      "\n",
      "[[379  25]\n",
      " [ 38 158]]\n",
      "No. of Estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       404\n",
      "           1       0.86      0.84      0.85       196\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.89      0.89      0.89       600\n",
      "weighted avg       0.90      0.90      0.90       600\n",
      "\n",
      "[[378  26]\n",
      " [ 32 164]]\n",
      "No. of Estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       404\n",
      "           1       0.87      0.85      0.86       196\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.90      0.90      0.90       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n",
      "[[379  25]\n",
      " [ 29 167]]\n",
      "No. of Estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       404\n",
      "           1       0.89      0.85      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.91      0.90      0.90       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "[[384  20]\n",
      " [ 30 166]]\n",
      "No. of Estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       404\n",
      "           1       0.89      0.85      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.91      0.90      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "[[384  20]\n",
      " [ 29 167]]\n",
      "No. of Estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       404\n",
      "           1       0.90      0.85      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.91      0.90      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "[[385  19]\n",
      " [ 29 167]]\n",
      "No. of Estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       404\n",
      "           1       0.90      0.84      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.91      0.90      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "[[386  18]\n",
      " [ 31 165]]\n",
      "No. of Estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94       404\n",
      "           1       0.90      0.85      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.92      0.90      0.91       600\n",
      "weighted avg       0.92      0.92      0.92       600\n",
      "\n",
      "[[386  18]\n",
      " [ 30 166]]\n",
      "No. of Estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       404\n",
      "           1       0.89      0.85      0.87       196\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.91      0.90      0.90       600\n",
      "weighted avg       0.91      0.92      0.91       600\n",
      "\n",
      "[[383  21]\n",
      " [ 30 166]]\n",
      "No. of Estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       404\n",
      "           1       0.90      0.87      0.89       196\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.92      0.91      0.92       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n",
      "[[386  18]\n",
      " [ 25 171]]\n",
      "No. of Estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       404\n",
      "           1       0.91      0.89      0.90       196\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.92      0.92       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n",
      "[[386  18]\n",
      " [ 22 174]]\n",
      "No. of Estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       404\n",
      "           1       0.92      0.89      0.90       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.93      0.92      0.93       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[388  16]\n",
      " [ 22 174]]\n",
      "No. of Estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       404\n",
      "           1       0.93      0.90      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.93      0.94       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[390  14]\n",
      " [ 20 176]]\n",
      "No. of Estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       404\n",
      "           1       0.93      0.90      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.93      0.94       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[390  14]\n",
      " [ 19 177]]\n",
      "No. of Estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       404\n",
      "           1       0.92      0.90      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.93      0.93      0.93       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[388  16]\n",
      " [ 20 176]]\n",
      "No. of Estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       404\n",
      "           1       0.92      0.90      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.93      0.93       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[388  16]\n",
      " [ 19 177]]\n",
      "No. of Estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       404\n",
      "           1       0.92      0.90      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.93      0.94       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[389  15]\n",
      " [ 19 177]]\n",
      "No. of Estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       404\n",
      "           1       0.91      0.91      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[387  17]\n",
      " [ 17 179]]\n",
      "No. of Estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       404\n",
      "           1       0.91      0.91      0.91       196\n",
      "\n",
      "    accuracy                           0.94       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.94      0.94      0.94       600\n",
      "\n",
      "[[387  17]\n",
      " [ 17 179]]\n",
      "No. of Estimators: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       404\n",
      "           1       0.91      0.93      0.92       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[387  17]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       404\n",
      "           1       0.91      0.93      0.92       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n",
      "[[387  17]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       404\n",
      "           1       0.91      0.93      0.92       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n",
      "[[387  17]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       404\n",
      "           1       0.92      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.94      0.95      0.95       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n",
      "[[389  15]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.93      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.95      0.95      0.95       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n",
      "[[391  13]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.94      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.95      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[392  12]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.94      0.94      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.95      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[392  12]\n",
      " [ 12 184]]\n",
      "No. of Estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.94      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.95      0.95      0.95       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[392  12]\n",
      " [ 14 182]]\n",
      "No. of Estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       404\n",
      "           1       0.94      0.94      0.94       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[393  11]\n",
      " [ 12 184]]\n",
      "No. of Estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n",
      "No. of Estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       404\n",
      "           1       0.95      0.94      0.95       196\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "[[394  10]\n",
      " [ 11 185]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for XGBClassifier class \n",
    "#her it has n_estimators means how many decision tree is use for train the model \n",
    "#n_estimators is >=10 and <=100 , we apply for-loop\n",
    "for i in range(10,101):\n",
    "    xgb = XGBClassifier(n_estimators=i,reg_alpha=1,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    xgb = create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cb1f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       404\n",
      "           1       0.91      0.93      0.92       196\n",
      "\n",
      "    accuracy                           0.95       600\n",
      "   macro avg       0.94      0.94      0.94       600\n",
      "weighted avg       0.95      0.95      0.95       600\n",
      "\n",
      "[[387  17]\n",
      " [ 14 182]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 34\n",
    "xgb = XGBClassifier(n_estimators=34,reg_alpha=1,random_state=1)\n",
    "#call function\n",
    "xgb = create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d1a6af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.314946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.152857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.144733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.105591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.100995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.093179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.087698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Input        IG\n",
       "0                   Glucose  0.314946\n",
       "1                       BMI  0.152857\n",
       "2               Pregnancies  0.144733\n",
       "3  DiabetesPedigreeFunction  0.105591\n",
       "4                   Insulin  0.100995\n",
       "5             SkinThickness  0.093179\n",
       "6             BloodPressure  0.087698"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Information Gain\n",
    "dict12 = {\"Input\":x.columns,\"IG\":xgb.feature_importances_}\n",
    "df13 = pd.DataFrame(dict12)\n",
    "df13.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we got the recall score 0.93(93%) which is best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70a938cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now giving the data to Support Vector Machine\n",
    "#1.Linear kernel function of Support Vector Machine means suppose data are linear\n",
    "#separatable with the help of straight line\n",
    "#call inbuilt class for Linear SVM : LinearSVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e162b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object for LinearSVC class\n",
    "svc = LinearSVC(random_state=1)   \n",
    "#no add any error means support no outlier in our dataset means it is hard margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25a5faf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       404\n",
      "           1       0.70      0.58      0.63       196\n",
      "\n",
      "    accuracy                           0.78       600\n",
      "   macro avg       0.75      0.73      0.74       600\n",
      "weighted avg       0.77      0.78      0.77       600\n",
      "\n",
      "[[354  50]\n",
      " [ 82 114]]\n"
     ]
    }
   ],
   "source": [
    "#call the function\n",
    "svc = create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By applying Support Vectors Machine in or dataset we got the recall score 0.58(58%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
